[
  {
    "objectID": "archive/index.html",
    "href": "archive/index.html",
    "title": "Miscellaneous documents",
    "section": "",
    "text": "Miscellaneous documents\n\nJornada Metadata Standards guide (out of date)\nJornada keywords thesaurus (also out of date)\nOld project and data documentation forms\nAn old ResNotif form for posterity"
  },
  {
    "objectID": "templates/index.html",
    "href": "templates/index.html",
    "title": "Forms and templates",
    "section": "",
    "text": "Forms and templates\nResearch approval\n\nTo request approval to conduct research at the Jornada, fill out the ResNotif form and send to Conrad Nelson.\n\nData submission and publishing\nWe strongly recommend using the Environmental Data Initiative‚Äôs ezEML application, but if this is not sufficient for your needs we have metadata templates that you may send to the Jornada IM team.\n\nMS Word format for relatively simple datasets with few tables.\nMS Excel format for more complex datasets with multiple tables.\n\nData requests\nMost data are openly available at the Jornada LTER website data catalog, but some spatial data are restricted access only.\n\nFill out the Spatial Data Request form to request restricted spatial data."
  },
  {
    "objectID": "docs/im/overview.html",
    "href": "docs/im/overview.html",
    "title": "Overview of Information Management at the Jornada",
    "section": "",
    "text": "Information Management at Jornada Basin LTER\nThis is the full documentation for the Jornada Basin LTER Information Management system, covering technical aspects of our data publishing process, data management tools, and administration of public-facing information like the website and data catalog. Researchers and data users should start at the Jornada IM web pages to get started with Jornada data management. This is a DRAFT document.\n\nTable of contents\nPreface: The JRN LTER Data Management Plan\nChapters:\n\nResearch & data management overview\n\nIntroduction\nResearch project management\nResearch data management\nPublic dataset listings\nBibliographies\nLocal servers\nHosted services (external)\n\nPolicy and procedures\n\nResearch notifications and approval\nData access policies\nMetadata and data submission\n\nGeneral systems administration\n\nServer & cloud administration\n\nData collection and quality assurance\n\nArchiving data on network shares\nGCE and MATLAB extensions\nScripted QA/QC\n\nMetadata collection and standards\n\nMetadata standards\n\nJRN Metabase\n\nInstallation and configuration\nServer and database administration\nThe LTER Metabase schema and data model\nPopulating a new database\nCreate and update datasets\nPostgreSQL help links\n\nPublishing Jornada datasets\n\nOverview, conventions, and standards\nMaking EML with JRN Metabase\n\nSOP for entering metadata in Metabase: docx, web page (draft)\n\nMaking EML with EMLassemblyline\n\nProject management\n\nProject database\nPersonnel updates\nPublication updates\n\nThe JRN website and other communication platforms\n\nThe JRN Website - an overview\nWebsite content\nWebsite apps\n\nThe data catalogs\nZotero bibliography\nInteractive data viewer\n\nShared mailing lists\n\nTools and apps\n\nGuide to Jornada-IM repositories\nAnalytics apps\nDSIS\n\nHacks\n\nParse trello boards to CSV format\n\nExternal data, partnerships, and collaboration\n\nCollaborations with USDA-ARS data managers\nAsombro data\nNEON data\n\nAnnual reports\n\n2020\n2021\n\n\nJornada data managers, including the IM team, should follow LTER and Jornada standards and best practices when creating metadata files and publishing research data packages.\n\n\n\nDataset tracking\nWe use Trello for this. For LTER datasets there are three Trello boards that represent how Jornada datasets are split into three categories:\n\nCore - ongoing, high priority datasets that are updated regularly (once per year we hope). Many of these are collected by the JRN field crew.\nNon-core - lower-priority and completed datasets.\nWorks in progress (‚ÄòWIP‚Äô) - datasets that are brand new or as-yet unpublished. Many are in the development/review phase, or are awaiting publication of results associated with the data.\n\nContact someone on the IM team to get added to these boards.\n\n\nData management resources\nIf you are wondering whether the content or format of a metadata file (EML) is correct and complete, see our metadata standards documents. They are specific to Jornada Basin LTER data packages. THESE ARE DRAFTS and subject to change!\n\nGeneral Jornada metadata standards for all data packages (this is a bit out of date)\nJornada keyword thesauri (.xlsx) list keywords that should appear in all Jornada metadata files.\nAlso see the full Jornada IM documentation pages",
    "crumbs": [
      "IM Guide",
      "Overview"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-01-overview.html",
    "href": "docs/im/sysadmin/chapter-01-overview.html",
    "title": "1. IM System Overview",
    "section": "",
    "text": "Introduction\nOur priorities in the Jornada IM team are to:\n\nContribute to high quality, impactful ecology and rangeland research at all stages of the data life cycle.\nOversee, or directly handle, publication of all Jornada datasets\n\nIn the process we ensure data meet FAIR data principles & the LTER Data Access Policy.\n\nAct as a source of data-related leadership and education\n\nWe do this through committee & working group participation, open-source software development, outreach activity, and teaching.\n\n\n\n\nResearch project management\nResearch projects at the Jornada are initiated by requesting approval using John Anderson‚Äôs ‚ÄúResearch notification‚Äù process. A summary of this process, and links to relevant documents are on the ‚ÄúFor researchers‚Äù page of the JRN and JER websites.\n\n\nData management\nData management expectations for researchers are also outlined on the JRN and JER websites. Field data collection of long-term datasets is typically handled by the Jornada Field Crew, under the supervision of John Anderson.\nQA/QC\nMetadata overview\n\n\nPublic dataset listings\nEDI\nPartner data\n\n\nBibliographies\nZotero, LTER network, etc.\n\n\nLocal computing resources\nJornada servers and network devices\n\n\nHosted resources\nDigital Ocean, website, NMSU stuff, ArcGIS Online (in addition to EDI/Zotero",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "1. IM System Overview"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-06-server-admin.html",
    "href": "docs/im/sysadmin/chapter-06-server-admin.html",
    "title": "6. Servers and Server Administration",
    "section": "",
    "text": "The Jornada IM system relies on some cloud servers at DigitalOcean (aka droplets). Generally these are running Ubuntu Server 20.04. Below are some tools and practices for setting up servers, networking between them, managing user access, transferring and securing data, and other administrative tasks.\n\n\nCreating new services at DO is easy - it can be done with the dashboard or an API. Documentation for all DO services is available here, and for droplets see the recommended initial setup docs here and here\n\nAdd public key to server - usually you can do this on creation or from an admin control panel. If it needs to be done after the fact see here\nAdd a non-root user with sudo privilege and allow ssh access. More info here:\n\nhttps://www.digitalocean.com/docs/droplets/tutorials/recommended-setup/\nhttps://www.digitalocean.com/community/questions/how-to-enable-ssh-access-for-non-root-users\n\nConfigure hostnames (if not already done at creation).\n\nhttps://www.digitalocean.com/community/questions/how-do-i-change-hostname\n\nInstall software, which varies depending on server purpose.\n\nMetabase server: git, cron, PostgreSQL\nWeb servers: probably the LAMP stack and WordPress, maybe some javascript.\n\n\n\n\n\nClone the LTER-core-metabase and jrn-db-utils (private) repositories to a directory in home.\nCreate a backups directory and mkdir /home/backups/postgresql. Make sure owner is whoever operates backups for postgres\nAdd a the jrn-db-utils/sh/pb_backup_rotated.sh script to crontab - nightly.\nMake sure incoming connections for SSH (TCP port 22) and PostgreSQL (TCP port 5432) are allowed in the firewall (currently using the DO firewall).\n\n\n\n\n\nDroplets are behind a DO cloud firewall, but if needed, firewalls can also be set up for individual droplets with UFW. This and other tasks are described in the initial server setup docs above, or:\n\nDigitalOcean droplet security tutorial\n\nUnattended updates are a good idea also. For Ubuntu install the unnattended-upgrades package and see setup instructions here.\n\n\n\nSome server tasks, like database or website backups, should be scheduled with cron.\n\nDO Ubuntu cron tutorial\n\n\n\n\nThe JORNADA-NETB1 storage block (sometimes called the R drive) allows CIFS connections (or SMB).\nOther:\n\nSetting up NFS mounts in Ubuntu",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "6. Servers and Server Administration"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-06-server-admin.html#cloud-server-setup-tasks",
    "href": "docs/im/sysadmin/chapter-06-server-admin.html#cloud-server-setup-tasks",
    "title": "6. Servers and Server Administration",
    "section": "",
    "text": "Creating new services at DO is easy - it can be done with the dashboard or an API. Documentation for all DO services is available here, and for droplets see the recommended initial setup docs here and here\n\nAdd public key to server - usually you can do this on creation or from an admin control panel. If it needs to be done after the fact see here\nAdd a non-root user with sudo privilege and allow ssh access. More info here:\n\nhttps://www.digitalocean.com/docs/droplets/tutorials/recommended-setup/\nhttps://www.digitalocean.com/community/questions/how-to-enable-ssh-access-for-non-root-users\n\nConfigure hostnames (if not already done at creation).\n\nhttps://www.digitalocean.com/community/questions/how-do-i-change-hostname\n\nInstall software, which varies depending on server purpose.\n\nMetabase server: git, cron, PostgreSQL\nWeb servers: probably the LAMP stack and WordPress, maybe some javascript.\n\n\n\n\n\nClone the LTER-core-metabase and jrn-db-utils (private) repositories to a directory in home.\nCreate a backups directory and mkdir /home/backups/postgresql. Make sure owner is whoever operates backups for postgres\nAdd a the jrn-db-utils/sh/pb_backup_rotated.sh script to crontab - nightly.\nMake sure incoming connections for SSH (TCP port 22) and PostgreSQL (TCP port 5432) are allowed in the firewall (currently using the DO firewall).",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "6. Servers and Server Administration"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-06-server-admin.html#securing-cloud-servers",
    "href": "docs/im/sysadmin/chapter-06-server-admin.html#securing-cloud-servers",
    "title": "6. Servers and Server Administration",
    "section": "",
    "text": "Droplets are behind a DO cloud firewall, but if needed, firewalls can also be set up for individual droplets with UFW. This and other tasks are described in the initial server setup docs above, or:\n\nDigitalOcean droplet security tutorial\n\nUnattended updates are a good idea also. For Ubuntu install the unnattended-upgrades package and see setup instructions here.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "6. Servers and Server Administration"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-06-server-admin.html#scheduled-tasks",
    "href": "docs/im/sysadmin/chapter-06-server-admin.html#scheduled-tasks",
    "title": "6. Servers and Server Administration",
    "section": "",
    "text": "Some server tasks, like database or website backups, should be scheduled with cron.\n\nDO Ubuntu cron tutorial",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "6. Servers and Server Administration"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-06-server-admin.html#nfs-and-cifs-mounts-to-remote-directories",
    "href": "docs/im/sysadmin/chapter-06-server-admin.html#nfs-and-cifs-mounts-to-remote-directories",
    "title": "6. Servers and Server Administration",
    "section": "",
    "text": "The JORNADA-NETB1 storage block (sometimes called the R drive) allows CIFS connections (or SMB).\nOther:\n\nSetting up NFS mounts in Ubuntu",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "6. Servers and Server Administration"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html",
    "title": "3. Websites and Web Applications",
    "section": "",
    "text": "The JRN website runs on Wordpress and is hosted by WPengine. The JRN webmaster, currently the lead Information Manager, has a WPengine.com account that allows access to the website backend for account management, website backups, and other administrative tasks. For content creation, editing, and website design, user accounts are created in the Wordpress environment.\n\n\nThere are 3 Wordpress environments available at the hosting provider.\n\nProduction - this is the live JRN website. Only the webmaster has editing rights in this environment and is responsible for pulling in changes from the staging environment.\nStaging - in close sync with the Production environment, new content such as blog posts and pictures can be created and tested here. The project manager and other staff have editing access in this environment.\nDevelopment - New plugins, themes, and other features are tested here and pushed to Staging when ready. This is mainly used by the webmaster or other developers.\n\nEach environment has a unique name and web address at {environment}.wpengine.com. The production environment is the live website, so the DNS entry for lter.jornada.nmsu.edu points to this site.\n\n\n\nThe hosting provider allows secure shell (ssh) access to any environment using an SSH gateway. See setup instructions here. Once set up, issuing the command\nssh {environment}@{environment}.ssh.wpengine.net\nshould put the user into a terminal session on the web server. To move a directory of files, such as one of our website‚Äôs client-side apps, from a local machine to the website, use scp. For example, to push the zotero-biblio app to an environment you might do:\nscp -r GitHub/zotero-biblio {environment}@{environment}.ssh.wpengine.net:/sites/{environment}/\nThere are occasional issues with the SSH Gateway at our hosting provider, so luckily, management of files with git is also supported. See the git setup instructions\n\n\n\nOnce logged in to the shell of the web server environment there are a number of Wordpress command-line utilities that are available. See the description here:\nhttps://developer.wordpress.org/cli/commands/\n\n\nFor example, to remove mixed comment by replacing ‚Äúhttp://‚Äù addresses with ‚Äúhttps://‚Äù issue this command from the shell:\nwp search-replace 'http://{environment}.wpengine.com' 'https://{environment}.wpengine.com'\n\n\n\n\nThe primary data catalog and the publication lists, including the bibliography and non-EDI data catalog, are client-side apps hosted on our website (lter-datacat and Zotero-JavaScript-Search-Client, respectively) . Placing these apps there, and updating them, means adding a folder to the website‚Äôs root directory. This is done using scp, generally (see above), or by pushing changes via git.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#environments",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#environments",
    "title": "3. Websites and Web Applications",
    "section": "",
    "text": "There are 3 Wordpress environments available at the hosting provider.\n\nProduction - this is the live JRN website. Only the webmaster has editing rights in this environment and is responsible for pulling in changes from the staging environment.\nStaging - in close sync with the Production environment, new content such as blog posts and pictures can be created and tested here. The project manager and other staff have editing access in this environment.\nDevelopment - New plugins, themes, and other features are tested here and pushed to Staging when ready. This is mainly used by the webmaster or other developers.\n\nEach environment has a unique name and web address at {environment}.wpengine.com. The production environment is the live website, so the DNS entry for lter.jornada.nmsu.edu points to this site.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#secure-file-management",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#secure-file-management",
    "title": "3. Websites and Web Applications",
    "section": "",
    "text": "The hosting provider allows secure shell (ssh) access to any environment using an SSH gateway. See setup instructions here. Once set up, issuing the command\nssh {environment}@{environment}.ssh.wpengine.net\nshould put the user into a terminal session on the web server. To move a directory of files, such as one of our website‚Äôs client-side apps, from a local machine to the website, use scp. For example, to push the zotero-biblio app to an environment you might do:\nscp -r GitHub/zotero-biblio {environment}@{environment}.ssh.wpengine.net:/sites/{environment}/\nThere are occasional issues with the SSH Gateway at our hosting provider, so luckily, management of files with git is also supported. See the git setup instructions",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#managing-wordpress-from-the-command-line",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#managing-wordpress-from-the-command-line",
    "title": "3. Websites and Web Applications",
    "section": "",
    "text": "Once logged in to the shell of the web server environment there are a number of Wordpress command-line utilities that are available. See the description here:\nhttps://developer.wordpress.org/cli/commands/\n\n\nFor example, to remove mixed comment by replacing ‚Äúhttp://‚Äù addresses with ‚Äúhttps://‚Äù issue this command from the shell:\nwp search-replace 'http://{environment}.wpengine.com' 'https://{environment}.wpengine.com'",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#pushing-changes-to-js-apps-lter-datacat-pub_list",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#pushing-changes-to-js-apps-lter-datacat-pub_list",
    "title": "3. Websites and Web Applications",
    "section": "",
    "text": "The primary data catalog and the publication lists, including the bibliography and non-EDI data catalog, are client-side apps hosted on our website (lter-datacat and Zotero-JavaScript-Search-Client, respectively) . Placing these apps there, and updating them, means adding a folder to the website‚Äôs root directory. This is done using scp, generally (see above), or by pushing changes via git.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#homepage",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#homepage",
    "title": "3. Websites and Web Applications",
    "section": "Homepage",
    "text": "Homepage\nA mix of static and dynamic content.\nThe ‚ÄúRecent posts‚Äù section is a post grid populated with Wordpress posts beloging to the ‚ÄòFeatured‚Äô category. To add a new post to this section, create a post and assign to this category. All ‚ÄúFeatured‚Äù posts created are collected on the featured post history page. This page is also where the ‚ÄúNews‚Äù link in the main menu goes.\nStill more to describe here‚Ä¶",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#about",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#about",
    "title": "3. Websites and Web Applications",
    "section": "About",
    "text": "About\nPages under this menu are mostly static content that has been adapted from earlier versions of the website. Mostly this content gets updated during website development pushes during proposal writing or midterm reviews.\n\nPersonnel\nThe StaffMembers plugin handles this - need to write up more on how this works‚Ä¶",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#research",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#research",
    "title": "3. Websites and Web Applications",
    "section": "Research",
    "text": "Research\nMostly static content - again, usually updated during proposal pushes.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#data",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#data",
    "title": "3. Websites and Web Applications",
    "section": "Data",
    "text": "Data\nThis menu contains 3 data catalogs:\n\nThe main LTER one\nSpatial data (static)\nThe partner catalog (still in development).\n\nThese are described below.\nThe Interactive Data Viewer is also here (and it needs to be documented somewhere‚Ä¶), as is the static species lists (that also need updating‚Ä¶).",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#publications",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#publications",
    "title": "3. Websites and Web Applications",
    "section": "Publications",
    "text": "Publications\nThere are both static and dynamic pages under the ‚ÄúPublications‚Äù menu. The Bibliography page is showing an app called zotero-biblio that reads our bibliography from a database hosted at Zotero.org. The Zotero-JavaScript-Search-Client app is written in javascript and was originally developed by Tim Whiteaker at BLE LTER. Our fork of this app, which has some customizations, is hosted and maintained in a GitHub repository. It is running on the Bibliography page through an iframe, but the app lives at https://lter.jornada.nmsu.edu/Zotero-JavaScript-Search-Client/complete_jrn.html on the website.\n\nThe Zotero bibliography\n\nTagging\nThere is a tagging system for tracking the relationship between publications in the bibliography and the Jornada LTER program.\n\nJRN funded signifies a work that was directly funded by the Jornada LTER grant, with some acknowledgement of that in the text.\nJRN assisted signifies a work that was supported by the LTER program in some way that is apparent in the text - Jornada LTER data are used, assistance from particular people, or the work is supported by one of our leveraged programs - but direct funding from the JRN LTER is not acknowledged.\nJRN related signifies a work that is related to the JRN LTER program through location, personnel (investigator coauthor), or research theme, but has no known direct or indirect support from the program. A number of USDA-ARS works on or near the Jornada fall in this category.\nJRN foundational is used to tag works that were instrumental in the development of the JRN research program, but did not occur as part of the JRN LTER program, usually because they are from before the JRN LTER program was initally funded.\nJRNStatusVerified is a tag to indicate that someone in the program has checked the publication and verified that one of the tags above is accurately applied.\n\n\n\n\nBooks\nThe Books page is a post grid populated with Wordpress posts beloging to the ‚ÄòBooks‚Äô category. To add new books, create a post and assign to this category.\nOther pages under the ‚ÄúPublications‚Äù menu are static content.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#outreach",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#outreach",
    "title": "3. Websites and Web Applications",
    "section": "Outreach",
    "text": "Outreach\nMostly static content but the GRFP, Short Course, and REU pages contain post grids that display posts under the ‚ÄúGraduate-fellowship-project‚Äù, ‚ÄúEcology-short-course‚Äù, and ‚ÄúREU-project‚Äù categories, respectively.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#for-researchers",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#for-researchers",
    "title": "3. Websites and Web Applications",
    "section": "For Researchers",
    "text": "For Researchers\nStatic page - should stay fairly in-sync with this JER page.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#data-catalogs",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#data-catalogs",
    "title": "3. Websites and Web Applications",
    "section": "Data catalogs",
    "text": "Data catalogs\nThe data catalog seen at https://lter.jornada.nmsu.edu/data-catalog/ is JRNs primary data catalog and is a javascript app called lter-datacat.\n\nlter-datacat\nThe lter-datacat app is written in javascript and was originally developed by Geovany Ramirez and Jason Coombs. It is running on the main data catalog page through an iframe, but the app lives at https://lter.jornada.nmsu.edu/lter-datacat/ on the website.\nThe app is hosted and maintained in a GitHub repository\n\n\nPartner data\nThis is in development on the staging website. It will list data held at repositories other than EDI.\nIn development, there is an instance of the Zotero-JavaScript-Search-Client tool running at https://lter.jornada.nmsu.edu/Zotero-JavaScript-Search-Client/complete_jrndata.html that can be i-framed in when ready.\n\n\nSpatial data\nThe spatial data catalog is basically just a list of layers that can be downloaded as kmz files. Nothing fancy.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#zotero-bibliography",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#zotero-bibliography",
    "title": "3. Websites and Web Applications",
    "section": "Zotero bibliography",
    "text": "Zotero bibliography\n\nMaintaining the Zotero app\nOnce you make changes to the repository you can upload the whole thing to our webhost using scp. The proper command would be:\nscp -prq GitHub/Zotero-JavaScript-Search-Client/* {envname}@{envname}.ssh.wpengine.net:~/sites/{envname}/Zotero-JavaScript-Search-Client/\nwhere {envname} is the environment name at the host (WPengine currently). You‚Äôd need to have some ssh keys set up.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#interactive-data-viewer",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#interactive-data-viewer",
    "title": "3. Websites and Web Applications",
    "section": "Interactive data viewer",
    "text": "Interactive data viewer",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#shared-nmsu-outlook-mailboxes",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#shared-nmsu-outlook-mailboxes",
    "title": "3. Websites and Web Applications",
    "section": "Shared NMSU Outlook mailboxes",
    "text": "Shared NMSU Outlook mailboxes\n\njornada.data@nmsu.edu\n\nThis address is displayed on the Jornada LTER and USDA websites as the contact address for data-related inquiries. It is also listed as the contact email address for metadata describing published Jornada datasets, including in most EML documents and packages at EDI or Ag Data Commons.\nMail recieved is forwarded (using a mailbox rule) to primary members of the Jornada IM Team and the mailbox can be accessed through the Outlook web app by those same primary IM Team members.\nPreviously a GMail account, datamanager.jrn.lter@gmail.com, was used for this purpose, and all mail to that address is now forwarded to the present address (jornada.data@nmsu.edu).\n\njornada.lter@nmsu.edu\n\nThis address is displayed on the Jornada LTER websites as the contact address for program-related inquiries. Its also the contact address for the Jornada LTER Google account and an admin/moderator on the JRN-L and JRNSTUDENT-L listserv accounts.\nMail recieved is forwarded (using a mailbox rule) to primary Jornada LTER staff members (lead PI, program manager, information manager) and the mailbox can be accessed through the Outlook web app by those same primary staff members.\nPreviously, the program manager‚Äôs personal GMail address had been listed for this purpose.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-03-websites-and-apps.html#gnu-mailman-lists-on-lists.nmsu.edu",
    "href": "docs/im/sysadmin/chapter-03-websites-and-apps.html#gnu-mailman-lists-on-lists.nmsu.edu",
    "title": "3. Websites and Web Applications",
    "section": "GNU Mailman lists on lists.nmsu.edu",
    "text": "GNU Mailman lists on lists.nmsu.edu\nThere are 3 lists assigned to Jornada LTER on NMSU‚Äôs listserv system:\n\nJRN-L@lists.nmsu.edu (or JRN-L@nmsu.edu)\n\nUsed for general-interest email broadcasts to anyone affiliated with the Jornada LTER or voluntarily following this list. People can subscribe to this using a form on our website homepage.\n\nJRNSTUDENT-L@lists.nmsu.edu (or JRNSTUDENT-L@nmsu.edu)\n\nUsed mainly by JRN staff to contact graduate and undergraduate students, or of students to broadcast messages for themselves. Anything sent to JRN-L gets sent to this list as well (automatically, without duplicates).\n\nJRNSTAFF-L@lists.nmsu.edu (or JRNSTAFF-L@nmsu.edu)\n\nCurrently unused.\n\n\nTo administer these one must be on the NMSU VPN, or on campus, and visit the admin portal for each. The addresses for these are https://lists.nmsu.edu/mailman/admin/{listname}, where {listname} is jrn-l, jrnstudent-l, or jrnstaff-l.\n\nManaging the lists\nWe use the basic list admin tools provided by Mailman - the site IM and PM mainly handle it (and are still learning).",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "3. Websites and Web Applications"
    ]
  },
  {
    "objectID": "docs/im/procedures/sop_metadata_publishing.html",
    "href": "docs/im/procedures/sop_metadata_publishing.html",
    "title": "SOP for updating datasets in metabase",
    "section": "",
    "text": "The following are resources that can be referred to for information needed in order to enter or update datasets.\nData Catalog: https://lter.jornada.nmsu.edu/data-catalog\nEDI Data Portal: https://portal.edirepository.org/nis/home.jsp\nTrello: (used to track the datasets and to see which need updating)\nDownload DBeaver - cloud server with several databases, used by the IM team to make edits. This process will only need to be done once.\nPassword: lter1234 (until you change the password elsewhere)\nNavigating the JORNADA_IM server:\nOpen NonCore_packages ü°™ find your data set ID of interest: (i.e., 210370001_grasshopperdata) ü°™\nOther resources for data:",
    "crumbs": [
      "IM Guide",
      "Procedures",
      "SOP for updating datasets in metabase"
    ]
  },
  {
    "objectID": "docs/im/procedures/sop_metadata_publishing.html#navigating-the-dbeaver-database-to-update-and-incorporate-datasets",
    "href": "docs/im/procedures/sop_metadata_publishing.html#navigating-the-dbeaver-database-to-update-and-incorporate-datasets",
    "title": "SOP for updating datasets in metabase",
    "section": "NAVIGATING THE DBEAVER DATABASE TO UPDATE AND INCORPORATE DATASETS:",
    "text": "NAVIGATING THE DBEAVER DATABASE TO UPDATE AND INCORPORATE DATASETS:\nThe following are instructions for navigating through the DBeaver database in order to enter in or update datasets using the resources outlined above.\n\nDBeaver:\n\nClick (on left-hand side) to drop-down each of the following:\n\n&gt;postgres\n&gt;jrn_metabase_dev\n&gt;Schemas\n&gt;lter_metabase\n&gt;Tables: (This is where the metadata is stored and where &gt; most of the edits are made)\n\n\n\n\n&gt;DataSet: enter ‚ÄúDataSetID‚Äù= 210370001 into search engine and &gt; Enter\n\nIf no results: Add new row by clicking &gt; {width=‚Äú0.15625in‚Äù &gt; height=‚Äú0.15625in‚Äù} icon at the bottom or highlight a row and &gt; click on ‚ÄúDuplicate current row‚Äù\nUpdate the following fields, if applicable:\n\nDataSetID: i.e., 210370001\nTitle: enter full title of the project, i.e., &gt; Grasshopper survey and substrate utilization data at the &gt; Jornada Basin LTER site, 1983 to 1985\nPubDate: date that it‚Äôs being published: 2021-11-16 &gt; (usually today‚Äôs date)\nAbstract: file name referenced from respective dataset &gt; folder on the Shared Drive i.e.¬†abstact.210370001.md\nShortName: i.e., TRANFALL (use name from file on &gt; Jornada_IM server or from ‚Äúproject‚Äù tab in &gt; jornada-prj-sheets on Google Drive)\nUpdateFrequency: options are notPlanned (if project is &gt; complete), annually, biannually, or asNeeded (if project &gt; is ongoing)\nMaintenanceDescription: options are complete, ongoing, &gt; or [NULL]\nAbstractType: file\nBoilerplateSetting: &gt; jrn-default{width=‚Äú6.249405074365704in‚Äù &gt; height=‚Äú1.734375546806649in‚Äù}\nSave by clicking &gt; ‚Äú{width=‚Äù0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save‚Äù button at the &gt; bottom.\n\n\n&gt;DataSetAttributes: enter ‚ÄúDataSetID‚Äù= 210370001 into search &gt; engine and Enter\n\nIf &gt;DataSetEntities has an EntityType dataTable, then &gt; proceed with the following.\nIf no results: Add new row by clicking &gt; {width=‚Äú0.15625in‚Äù &gt; height=‚Äú0.15625in‚Äù} icon at the bottom or highlight a row and &gt; click on ‚ÄúDuplicate current row‚Äù\nTo enter multiple rows, right click ü°™ Advanced Paste ‚Ä¶ ü°™ &gt; Insert multiple rows\nReference the data sets found on JORNADA_IM server. These are &gt; also the files entered in &gt;DataSetEntities:\n\nDataSetID: 210370001\nEntitySortOrder: i.e.¬†1 for all within the same dataset, &gt; 2 for all within the next dataset, etc.\nColumnPosition: i.e.¬†1, 2, 3, 4‚Ä¶etc. for each row\nColumnName: reference the data located in the metadata &gt; template or data file. i.e., (jgrashop.dsd) Date, Plot, &gt; Transect, Quadrat, Species, Mean_Diameter, Mean_Height, &gt; Total_Number\nAttributeID: i.e.¬†Date, Plot, Transect, Quadrat, &gt; Species, Mean_Diameter, Mean_Height, Total_Number &gt; Repeat whatever is in ColumnName?\nAttributeLabel: i.e.¬†Date, Plot, Transect, Quadrat, &gt; Species, Mean_Diameter, Mean_Height, Total_Number &gt; Repeat whatever is in ColumnName?\nDescription: i.e., Date, Plot number [10-18], Transect &gt; number [1-2], Quadrat number [1-20], Species code &gt; [see JornadaGrasshopperDatasetCodes.txt], Mean plant &gt; diameter [cm], Mean plant height [cm], Total number of &gt; individuals per square meter per quadrat\nStorage Type: i.e., Date = date; plot, quadrat, transect &gt; number, or total number = integer; mean diameter or height &gt; = float; species code = string\nMeasurementScaleDomainID: Date = dateTime; integer = &gt; interval; float = ratio; string = nominalText\nDateTimeFormatString: ONLY on rows with column name &gt; ‚Äúdate‚Äù, all others should be [NULL]. Always YYYY/MM/DD &gt; format.\nDateTimePrecision: 1 on rows filled out as above, all &gt; others should be [NULL].\nTextPatternDefinition: any nominal text doesn‚Äôt need a &gt; unit and can be added to that row as ‚Äúany text‚Äù. All &gt; others should be [NULL].\nUnit: ‚Äúnumber‚Äù for intervals or ‚Äúcentimeter‚Äù for ratios. &gt; Date and nominal text should be [NULL].\nNumberType: ‚Äúinteger‚Äù for intervals or ‚Äúreal‚Äù for &gt; ratios. Date and nominal text should be [NULL].\n\nRepeat for each file in the server.\nIf a certain unit can‚Äôt be found, it must be added to the EML &gt; unit dictionary.\nBased on the R script console, any column with NA values &gt; requires a line entry. If it is missing info, such as NA, in &gt; the dataset, it will require an NA1 value (check define &gt; description).\nSave by clicking &gt; ‚Äú{width=‚Äù0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save‚Äù button at the &gt; bottom.{width=‚Äú5.671875546806649in‚Äù &gt; height=‚Äú3.4432174103237094in‚Äù}\n\n&gt;DataSetEntities (to associate/attach files): enter &gt; ‚ÄúDataSetID‚Äù= 210370001 into search engine and Enter\n\nThe files (.pdf, .TIF, csv) found in Jornada_IM server, under &gt; the file name i.e.¬†21037001_GrasshopperData, are used to &gt; update the following columns, if applicable:\n\nEntitySortOrder: change to subsequent number i.e.¬†2, 3, &gt; 4\nEntityName: change to something short but descriptive: &gt; Plant and grasshopper species codes\nEntityType: to dataTable (if dataTable, add &gt; DataSetAttributes) or otherEntity\nEntityDescription: something longer, uniform, and more &gt; descriptive: Numerical and species codes for plants and &gt; grasshoppers\nFileType: usually csv_B (most files) or plaintext\nUrlhead: &gt; https://sfo3.digitaloceanspaces.com/jrn-pubfiles/\nFile Name: enter exact file name: &gt; JRN_37001_grasshopper_substrate_data.csv\nFileSizeUnits: byte\n\nFor each data set, highlight row and click on &gt; {width=‚Äú0.13541666666666666in‚Äù &gt; height=‚Äú0.13541666666666666in‚Äù} icon at the bottom to &gt; ‚ÄúDuplicate current row‚Äù. Then update columns as above.\nSave by clicking &gt; ‚Äú{width=‚Äù0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save‚Äù button at the bottom.\n\n\n\n\n&gt;DataSetKeywords: enter ‚ÄúDataSetID‚Äù= 210370001 into search &gt; engine and Enter\n\nIf no results: Add new row, multiple rows, or duplicate rows as &gt; instructed above.\nUpdate columns as follows:\n\nDataSetID: i.e., 210370001\nKeyword: enter one word per row that has to do with the &gt; project i.e., grasshoppers, vegetation, abundance, etc‚Ä¶ &gt; Use metadata template in file folder on Jornada_IM &gt; server.\n\nAlways use study number i.e., study 370. This is done by &gt; adding it to ListKeywords. Any keywords that do not &gt; exist yet, can be added in ListKeywords.\n\nThesaurusID: lter_cv or jornada_placenames if it is a &gt; location/place. If it is the study ID i.e., study 370 - &gt; then ThesaurusID should be jornada_projectnames\n\n{width=‚Äú0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save\n\n&gt;DataSetMethod: enter ‚ÄúDataSetID‚Äù= 210370001 into search engine &gt; and Enter\n\nIf no results: Add new row or duplicate row as instructed above.\nUpdate columns as follows:\n\nDataSetID: i.e., 210370001\nMethodStepID: 1\nDescriptionType: file\nDescription: methods.210370001.md\nMethod_xml: [NULL]\n\nCreate method and abstract markdown files.\n\nMake sure method and abstract is in R file.\n\n\n&gt;DataSetPersonnel: enter ‚ÄúDataSetID‚Äù= 210370001 into search &gt; engine and Enter\n\nIf no results: Add new row, multiple rows, or duplicate rows as &gt; instructed above.\n\nEnter each row with the name of people involved i.e., &gt; dpeters\n\nUpdate columns as follows:\n\nDataSetID: i.e., 210370001\nNameID: Select cell and type name into Value box on &gt; right-hand side‚Ä¶.. i.e., dlightfoot, wwhitford. When the &gt; name appears in the Dictionary section, click to populate &gt; it into the NameID field. Repeat for each name. If you &gt; don‚Äôt see the NameID of the person you are looking for pop &gt; up on the right-hand side, you will need to add their &gt; names under ListPeople\n\n{width=‚Äú5.182292213473316in‚Äù &gt; height=‚Äú1.4975448381452319in‚Äù}\n\nAuthorshipOrder: 1, 2, 3‚Ä¶\nAuthorshipRole: i.e., creator, contact\n\n{width=‚Äú0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save\n\n&gt;DataSetPublications:\n\nIf applicable, update columns as follows:\n\nDataSetID: i.e., 210370001\nRelationshipType: usageCitation or literatureCited\n\n\n&gt;DataSetSites: enter ‚ÄúDataSetID‚Äù= 210370001 into search engine &gt; and Enter\n\nIf no results: Add new row, multiple rows, or duplicate rows as &gt; instructed above.\nUpdate columns as follows:\n\nDataSetID: i.e., 210370001\nEntitySortOrder: 0\nSiteID: i.e., Bajada_West, Basin_Floor, &gt; JER_CDRRC_bounding (general use)\nGeoCoverageSortOrder: 1, 2\n\n{width=‚Äú0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save\n\n&gt;DataSetTaxa: This is where you can link taxonomic data to a &gt; dataset.\n\nUpdate columns as follows:\n\nDataSetID: i.e., 210XXXXXX\nTaxonID: enter the ITIS number you obtained from &gt; ITIS.gov in the &gt;ListTaxa section.\nTaxonomicProviderID: i.e., itis\n\n{width=‚Äú0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save\n\n&gt;DataSetTemporal: enter ‚ÄúDataSetID‚Äù= 210370001 into search &gt; engine and Enter\n\nIf no results: Add new row, multiple rows, or duplicate rows as &gt; instructed above.\nUpdate columns as follows:\n\nDataSetID: i.e., 210370001\nEntitySortOrder: 0\nBeginDate and EndDate: (make sure it‚Äôs in proper &gt; YYYY/MM/DD format)\n\nThis can be found on the Google share drive, in the &gt; jornada-prj-sheets spreadsheet, under the Project tab.\n\nUseOnlyYear: [ ] uncheck if updated dates include &gt; month/day\n\n\n&gt;ListKeywords: If there are keywords to add in DataSetKeywords &gt; that are not found, they can be added here. Include any key words &gt; that should be associated with the project.\n\nControl F to double check that the word doesn‚Äôt already exist. &gt; If it doesn‚Äôt, add it as follows\nAdd row and include:\n\nKeyword: Study 370,\nThesaurusID: jornada_projectnames\nKeywordType: theme\n\nInclude any other relevant keywords that weren‚Äôt found when &gt; searching in DataSetKeywords. Other examples include:\n\nKeyword: creosotebush; Chihuahuan Desert\nThesaurusID: (look on &gt; https://vocab.lternet.edu/vocab/vocab/index.php &gt; for word, if it‚Äôs there enter as lter_cv; if not enter as &gt; none. If it‚Äôs a place, such as site, etc., &gt; jornada_placenames\nKeywordType: theme; place\n\n\n{width=‚Äú0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save\n\n&gt;ListPeople: To update the creators involved with a project.\n\nDuplicate a current row in order to add people. If it has new &gt; personnel, then\nTo delete a row, highlight row and click ‚ÄúDelete Current Row‚Äù at &gt; the bottom. It will highlight red so you must Save in order to &gt; save changes.\n\n&gt;ListPublications (to attach publications with data sets):\n\nUpdate columns as follows:\n\nPublicationID: i.e.,\nBibtex:\n\n\n&gt;ListTaxa: This is where you can enter taxonomic data. First go &gt; to ITIS.gov to search for the ITIS Taxa ID if species is not &gt; already listed in this section.\n\nUpdate columns as follows:\n\nTaxonID: enter the ITIS number you obtained from &gt; ITIS.gov\nTaxonomicProviderID: itis\nTaxonRankName: species\nTaxonRankValue: Genus species name i.e., Bos taurus\nCommonName: i.e., domesticated cattle\nLocalID: ID found through ITIS.gov i.e., cow or BOER4\n\n{width=‚Äú0.15207020997375328in‚Äù &gt; height=‚Äú0.15228127734033245in‚Äù} Save",
    "crumbs": [
      "IM Guide",
      "Procedures",
      "SOP for updating datasets in metabase"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html",
    "href": "docs/im/standards/JRN_metadata_standards.html",
    "title": "Jornada Dataset Metadata Standards",
    "section": "",
    "text": "If you edit this document please track your changes and send to Greg Maurer (gmaurer.jrn.lter@gmail.com).\nNotes about things that need to be expanded or verified are marked with ‚Äú???‚Äù",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#using-this-document",
    "href": "docs/im/standards/JRN_metadata_standards.html#using-this-document",
    "title": "Jornada Dataset Metadata Standards",
    "section": "Using this document",
    "text": "Using this document\nThe metadata standards in this document are structured and formatted similarly to an EML document. Named EML elements are surrounded by angle brackets, and there are headings for most important elements. At the Jornada Basin LTER, a variety of tools are being used to create EML documents during the data packaging process (EMLassemblyline, GCE Toolbox +, etc.). Notes about using these tools to create each EML element are present in the relevant section of this document (???Add these in as you edit).\nNote that EML documents are hierarchical. The root element is &lt;eml:eml&gt; (denoted by the path /eml:eml). Below the EML root element are 3 elements, &lt;access&gt;, &lt;dataset&gt;, and &lt;additional_metadata&gt; (paths /eml:eml/access, /eml:eml/dataset, and /eml:eml/additional_metadata). This document contains metadata standards for elements under the &lt;dataset&gt; element of Jornada EML files only. We may add standards for EML &lt;access&gt; and &lt;additional_metadata&gt; elements at a later time.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#title",
    "href": "docs/im/standards/JRN_metadata_standards.html#title",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<title>*",
    "text": "&lt;title&gt;*\n* This is a required element.\nThe &lt;title&gt; element should contain a descriptive title that includes type of data collected, geographic indicator, and temporal range of the data (what, where, when). Keep in mind that package titles are searchable and are a user‚Äôs first point of contact when searching for data packages.\nBest practices:\n\nFor the title‚Äôs geographic indicator all Jornada Basin LTER data packages should include ‚ÄúJornada Basin LTER‚Äù.\nIf the data come from an established study with a name or acronym, include the name or acronym in the title (NPP study, SMES, NEAT, etc.)\nFor the temporal range of completed data packages give the starting year of the data to the ending year; ‚Äú2009-2015‚Äù, for example.\nFor the temporal range of ongoing data packages there are 2 possibilities:\n\nWrite the end of the temporal range as a year if data collection occurs less frequently than yearly (‚Äú2010-2018‚Äù for a package collected every 2 years).\nWrite the end of the temporal range as ‚Äúongoing‚Äù if data collection occurs yearly or more frequently (‚Äú2010-ongoing‚Äù if data were last updated a year ago or less).",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#personnel-and-organization-elements-creator-project-etc.",
    "href": "docs/im/standards/JRN_metadata_standards.html#personnel-and-organization-elements-creator-project-etc.",
    "title": "Jornada Dataset Metadata Standards",
    "section": "Personnel and organization elements (<creator>, <project>, etc.)",
    "text": "Personnel and organization elements (&lt;creator&gt;, &lt;project&gt;, etc.)\nThere are a number of elements in this category grouped together here. They normally appear within the &lt;dataset&gt; element (/eml:eml/dataset/creator, /eml:eml/dataset/contact, etc)\nAt least one &lt;contact&gt; element must be supplied in every EML document. All EML documents should have at least one person in a &lt;creator&gt; element, but exceptions can be made if this information has been lost in very old Jornada data packages.\n\n&lt;contact&gt;*\n* This is a required element.\nContacts are people (or positions, like Data Manager) that should be contacted for access to, or information about, the data package. For Jornada data packages this should include:\n\nThe ‚ÄúCurrent responsible investigator‚Äù (if available)\nThe JRN LTER Information Manager (datamanager.jrn.lter@gmail.com)\n\nJRN LTER defines the ‚ÄúCurrent responsible investigator‚Äù as the LTER principal investigator who curates a study and its associated data package(s). For data packages without a ‚Äúcurrent responsible PI‚Äù, John Anderson has historically been listed with this role under &lt;contact&gt;. When updating one of these packages, ask John if he would like to remain in this position. If not, he may be removed and it is acceptable to list only the Data Manager.\nNo other contacts are defined.\n\n\n&lt;creator&gt;*\n*This is a required element.\nCreators are people with direct intellectual contributions to the data package and so could include PIs, postdocs, students, and other researchers. There can be multiple &lt;creator&gt; elements in a Jornada EML document. These should include:\n\nOriginal PIs\nFormer responsible PIs\nCurrent responsible PIs\nPostDocs, grad students, and other researchers (??? need to verify this)\n\nIf for some reason the original PI for the data package is unknown, it is acceptable to list the Jornada Basin LTER as an organization in the &lt;creator&gt; element.\n\n\n&lt;project&gt;\nThis element should be included in EML for all JRN data packages and should contain the &lt;title&gt;, &lt;organization&gt;, &lt;funding&gt;, and &lt;personnel&gt; sub-elements within it. List the Jornada Basin LTER as the project &lt;title&gt;, New Mexico State University as &lt;organization&gt;, and the current responsible PI for the data package as the &lt;personnel&gt;. The &lt;funding&gt; element should include the NSF award number (DEB-1832194 or similar) that was active when the project was initiated.\nThis element is created automatically by EMLassemblyline if a personnel entry is listed with the role ‚ÄúPI‚Äù.\nProvisional change: If there is no current responsible PI for a completed package, it may be acceptable to omit the &lt;project&gt;&lt;personnel&gt; element as long as the other elements are complete. (??? need to verify this is ok)\n\n\nOther personnel and organization elements\nOther personnel and organization elements, such as &lt;metadataProvider&gt;, &lt;associatedParty&gt;, or &lt;publisher&gt;, can be defined in EML and have been included in Jornada Basin LTER data packages. There is no standardized policy for these yet, so when updating such packages, preserve these elements if possible.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#pubdate",
    "href": "docs/im/standards/JRN_metadata_standards.html#pubdate",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<pubDate>",
    "text": "&lt;pubDate&gt;\nDefault for this at EDI and LTER sites appears to be that &lt;pubDate&gt; refers to the date of the latest metadata revision for a data package posted on EDI.\nAt JRN, this element has had other meanings (first date of publication), but there isn‚Äôt currently a consistent policy.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#abstract",
    "href": "docs/im/standards/JRN_metadata_standards.html#abstract",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<abstract>",
    "text": "&lt;abstract&gt;\nA descriptive abstract of the data package, with enough context for a user to decide whether it is useful to them, should be included here. Keep in mind that package abstracts are used in full-text searches\nBest practices:\n\nInclude a brief statement about whether data collection is ‚Äúongoing‚Äù or ‚Äúcompleted‚Äù.\nInclude a brief description of data collection and data package update frequency (‚Äúupdated monthly/yearly/every spring‚Äù).\nInclude information on whether the data were collected on the ‚ÄúJornada Experimental Range‚Äù, on the ‚ÄúCDRCC‚Äù, or on both.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#keywordset",
    "href": "docs/im/standards/JRN_metadata_standards.html#keywordset",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<keywordSet>",
    "text": "&lt;keywordSet&gt;\nMultiple &lt;keywordSet&gt; elements can be defined. Optionally they may be labeled with a specific vocabulary they are taken from using the &lt;keywordThesaurus&gt; tag. The Jornada Basin LTER uses these keyword thesauri:\n\nLTER Controlled Vocabulary - required to describe the subject matter of each data package\nJornada-specific thesauri - currently there are 3, which are still in development.\n\n‚ÄúJRN Dataset Keywords‚Äù include subject matter, funding, time span, and other JRN LTER specific terms.\n‚ÄúJornada Project Names‚Äù include the descriptive names of abbreviations of studies or projects taking place in Jornada Basin (affiliated with JRN LTER or not)\n‚ÄúJornada Place Names‚Äù include the place names of important study locations or geographic features. These overlap with the ‚ÄúJornada Place Names‚Äù in many cases.\n\nLTER Core Areas\nEML creators can also define keywords independent of these vocabularies (no &lt;keywordThesaurus&gt; tag).\n\nFrom the Jornada-specific thesauri, be sure to include:\n\nAt least one subject matter term from the ‚ÄúJRN Dataset Keyword‚Äù list.\nAny relevant terms from the ‚ÄúJornada Project Names‚Äù list\nAny relevant placenames from the ‚ÄúJornada Place Names‚Äù list\nThe Jornada study ID as ‚Äústudy {NNN}‚Äù, where {NNN} is the 3 digit study ID within the package ID (middle 3 digits). List this as a ‚ÄúJornada Project Name‚Äù keyword.\n\nThe keywords ‚Äúcore‚Äù and ‚Äúsignature‚Äù may be added to EML documents, but the plan at this point is to keep a separate list of packages with these designations and then cross-reference those lists during searches of the JRN data catalog.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#intellectualrights",
    "href": "docs/im/standards/JRN_metadata_standards.html#intellectualrights",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<intellectualRights>",
    "text": "&lt;intellectualRights&gt;\nThe Jornada Basin LTER uses the CC-BY attribution license, appended with the LTER network‚Äôs suggested data access policy text. There is a template in EMLassemblyline for this.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#coverage",
    "href": "docs/im/standards/JRN_metadata_standards.html#coverage",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<coverage>",
    "text": "&lt;coverage&gt;\nA &lt;coverage&gt; element can be defined at multiple levels in the EML document: for a &lt;dataset&gt; element (/eml:eml/dataset/coverage), for a data entity (eml:eml/dataset/[entity]/coverage), within a &lt;methods&gt; element (eml:eml/dataset/methods/sampling/studyExtent/coverage), etc. Within each &lt;coverage&gt; element, three types of coverage elements can be defined - &lt;geographicCoverage&gt;, &lt;taxonomicCoverage&gt;, and &lt;temporalCoverage&gt;.\nFor now, at JRN LTER, we are focusing on providing adequate &lt;coverage&gt; metadata at the &lt;dataset&gt; element level, and there aren‚Äôt known standards for elements below this level (???). This is described in the sections below.\n\n&lt;geographicCoverage&gt;\nCoordinates for Jornada data packages are obfuscated (deliberately, due to security concerns) in most cases. How, and how much, to provide spatial data is a matter of debate at JRN LTER. The general practice is to provide one or more bounding boxes surrounding the research sites in a data package, but these bounding boxes should not be detailed enough to allow casual visitors to EDI to identify sensitive research sites or instrumentation. Some packages, however, already have finer details in the &lt;geographicCoverage&gt; elements. In these cases the person packaging the data should probably preserve this metadata, and has some discretion on how to proceed after consulting with PIs. The general guideline for this element is outlined below.\nFor &lt;dataset&gt; elements, define at least one &lt;geographicCoverage&gt; element. This &lt;geographicCoverage&gt; element should contain at least one bounding box that encloses all research locations for all data entities in the package. When possible, multiple bounding boxes may be provided as additional &lt;geographicCoverage&gt; elements that describe other study or sampling areas (these may be associated with locational variables in a data entity if you are clever about it). The bounding boxes should be large enough to prevent casual users from identifying the sites (on the EDI map interface, for example).\nEach &lt;geographicCoverage&gt; element should have a &lt;geographicDescription&gt; element associated that describes the location defined by the bounding boxes (or points, as the case may be) and include the text ‚ÄúHigher resolution spatial data for this data package can be obtained by contacting the Data Manager‚Äù.\n\n\n&lt;taxonomicCoverage&gt;\nThere are many systems for denoting taxonomic entities or groups, including local systems that are specific to the Jornada Basin LTER or its researchers. JRN data packages that contain taxonomic data (data attributes of species, groups of species, or other taxa) should provide ways to identify the taxonomic entities or groups in a &lt;dataset&gt; to modern, accepted taxonomic classifications at the Genus species or finer levels.\nThese links may be provided in a variable or category in the data entity itself (a ‚ÄúGenus_species‚Äù variable, or example), as long as they are properly attributed to an authority like ITIS or USDA PLANTS. Local (JRN specific) taxonomic keys or coding systems that appear in a data entity must be available to the data user. In these cases the keys or coding systems used should be described in the metadata and provided as either an additional data entity in the data package, or as a link to other JRN EDI packages with this information.\nSome current Jornada taxonomic keys are:\n\nKey to vascular plants in the Jornada Basin (an EDI package)\n\n\n\n&lt;temporalCoverage&gt;\nProvide the start and end date of the period over which the data were collected. For &lt;dataset&gt; elements this should include the data in all data entities (all .csv or other data files) that the EML document defines.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#maintenance",
    "href": "docs/im/standards/JRN_metadata_standards.html#maintenance",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<maintenance>",
    "text": "&lt;maintenance&gt;\nDescribes whether data collection is ongoing or completed (in &lt;description&gt; element) and may include descriptions of the frequency of data and metadata changes (in &lt;frequency&gt; element).\n\nDescribe the data package as ‚Äúcompleted‚Äù if data collection has ended.\nDescribe the data package as ‚Äúongoing‚Äù if data collection continues.\nFor ‚Äúongoing‚Äù data packages, a description of how often package revisions, including data and metadata changes, occur should be added to the &lt;frequency&gt; element under &lt;maintenance&gt;. For example, if new data are QA/QC‚Äôd, appended to a data entity, and published for a data package every month, the &lt;frequency&gt; element should describe these ‚Äúmonthly‚Äù revisions.\nOptionally, and in addition to #3 above, the &lt;frequency&gt; element under &lt;maintenance&gt; can describe the frequency (hourly, daily, bimonthly, etc.) of the data in any data entities in the package. This may be especially important tabular time series.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#methods",
    "href": "docs/im/standards/JRN_metadata_standards.html#methods",
    "title": "Jornada Dataset Metadata Standards",
    "section": "<methods>",
    "text": "&lt;methods&gt;\nThis element should include a detailed description of how the data were collected or otherwise derived (field procedures, laboratory analysis, data synthesis and analysis). It should be concise but sufficient to reproduce the resulting data entity in the package.\nMany Jornada packages have &lt;methods&gt; elements that refer to ancillary procedures documents, QA/QC specifications, data reduction scripts, etc. Whenever possible these should be preserved and archived as additional data entities in the data package (or at least a link to another repository should be provided).\nIf needed &lt;methods&gt; elements can be defined for individual data entities (/eml:eml/dataset/[entity]/methods). A hierarchy of additional elements, such as &lt;instrument&gt;, &lt;sampling&gt;, &lt;methodStep&gt;, &lt;qualityControl&gt;, can be also defined within each &lt;methods&gt; element. The GCE Toolbox+ does some of this for us with Jornada met data. In general though, descriptive text with optional pointers to other methods documentation is usually adequate.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/im/standards/JRN_metadata_standards.html#data-entities",
    "href": "docs/im/standards/JRN_metadata_standards.html#data-entities",
    "title": "Jornada Dataset Metadata Standards",
    "section": "Data entities",
    "text": "Data entities\nThese define the actual data files in the package (.csv files, rasters, etc). There can be more than one in a package.\nSeveral possible elements are used to define individual data entities within a &lt;dataset&gt;. These include &lt;dataTable&gt;, &lt;spatialRaster&gt;, &lt;spatialVector&gt;, &lt;storedProcedure&gt;, &lt;view&gt;, and &lt;otherEntity&gt;. Each of these must contain other elements that describe the data they contain (the EntityGroup tree). The most important of these, for us, is the &lt;attributeList&gt; that defines the variables in a &lt;dataTable&gt; entity, since most Jornada data is tabular.\nThere are not any Jornada-specific metadata standards for data entities (???maybe there should be) or the elements they contain (&lt;attributeList&gt;). Use EML best practices.",
    "crumbs": [
      "IM Guide",
      "Metadata standards",
      "Jornada Dataset Metadata Standards"
    ]
  },
  {
    "objectID": "docs/refs_and_links.html",
    "href": "docs/refs_and_links.html",
    "title": "Miscellaneous resources",
    "section": "",
    "text": "FAIR stands for Findable, Accessible, Interoperable, and Re-usable\n\nFAIR principles for scientific data\nRecent commentary on fair principles\n\n\n\n\n\nHadley Wickham‚Äôs ‚ÄúTidy‚Äù data paper and vignette\n\n\n\n\nJornada Basin LTER data packages are generally submitted to the EDI (Environmental Data Initiative) repository. They have resources about data collection, curation, and publishing.\n\nData authors guide (Please contact the Jornada IM team before following the guide)\nMore detailed data publishing best practices\nEDI‚Äôs 5 phases of data publishing (old EDI website)\n\n\n\n\n\nOrientation to data management at Jornada (JRN Ecology Short Course, July 2022)\nNavigating the Jornada Data Ecosystem (Jornada Symposium 2020)\n\n\n\n\nGries, C., S. Beaulieu, R.F. Brown, S. Elmendorf, H. Garritt, G. Gastil-Buhl, H. Hsieh, L. Kui, M. Martin, G. Maurer, A.T. Nguyen, J.H. Porter, A. Sapp, M. Servilla, and T.L. Whiteaker. 2021. Data Package Design for Special Cases ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/9d4c803578c3fbcb45fc23f13124d052"
  },
  {
    "objectID": "docs/refs_and_links.html#fair-data",
    "href": "docs/refs_and_links.html#fair-data",
    "title": "Miscellaneous resources",
    "section": "",
    "text": "FAIR stands for Findable, Accessible, Interoperable, and Re-usable\n\nFAIR principles for scientific data\nRecent commentary on fair principles"
  },
  {
    "objectID": "docs/refs_and_links.html#data-collection-and-management-advice",
    "href": "docs/refs_and_links.html#data-collection-and-management-advice",
    "title": "Miscellaneous resources",
    "section": "",
    "text": "Hadley Wickham‚Äôs ‚ÄúTidy‚Äù data paper and vignette"
  },
  {
    "objectID": "docs/refs_and_links.html#lteredi-resources",
    "href": "docs/refs_and_links.html#lteredi-resources",
    "title": "Miscellaneous resources",
    "section": "",
    "text": "Jornada Basin LTER data packages are generally submitted to the EDI (Environmental Data Initiative) repository. They have resources about data collection, curation, and publishing.\n\nData authors guide (Please contact the Jornada IM team before following the guide)\nMore detailed data publishing best practices\nEDI‚Äôs 5 phases of data publishing (old EDI website)"
  },
  {
    "objectID": "docs/refs_and_links.html#jornada-presentations",
    "href": "docs/refs_and_links.html#jornada-presentations",
    "title": "Miscellaneous resources",
    "section": "",
    "text": "Orientation to data management at Jornada (JRN Ecology Short Course, July 2022)\nNavigating the Jornada Data Ecosystem (Jornada Symposium 2020)"
  },
  {
    "objectID": "docs/refs_and_links.html#publications",
    "href": "docs/refs_and_links.html#publications",
    "title": "Miscellaneous resources",
    "section": "",
    "text": "Gries, C., S. Beaulieu, R.F. Brown, S. Elmendorf, H. Garritt, G. Gastil-Buhl, H. Hsieh, L. Kui, M. Martin, G. Maurer, A.T. Nguyen, J.H. Porter, A. Sapp, M. Servilla, and T.L. Whiteaker. 2021. Data Package Design for Special Cases ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/9d4c803578c3fbcb45fc23f13124d052"
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER7.html",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER7.html",
    "title": "Data Management Plan",
    "section": "",
    "text": "Note: This version was subsequently edited by Steve Archer and Greg Maurer before inclusion in the 2020 JRN LTER-VII proposal (table removed, formatting, rewording). The content and intent remains the same.\n\n\nThe core goals of the Information Management (IM) system at the Jornada Basin LTER (JRN) are to support and enhance investigations and data collection, and to make data and other scientific products openly accessible to the science community, resource managers, policy makers, and the public. We are meeting these goals by addressing five IM priorities: (1) design and implement efficient systems to collect, quality-assure, document, and archive research data; (2) annotate research data with complete, standardized metadata; (3) timely publication of data and metadata in accepted research data repositories; (4) promote and facilitate discovery and re-use of JRN research data; and (5) advance sound data management and sharing practices at JRN through leadership and educational activities. The lead Information Manager and other staff use diverse technologies to advance these priorities and hold monthly meetings with JRN PIs to allow oversight of IM activities and promote the development of new goals and procedures.\nOwing to IM deficiencies identified in the renewal proposal review, NSF granted JRN a probationary 2-year LTER award (instead of a full 6-year award) in 2018. A key concern was that JRN data packages were not routinely entered and updated in the Environmental Data Initiative‚Äôs data repository (EDI). In response, we: (1) hired a new lead IM (Dr.¬†Greg Maurer, started May 1, 2019), who regularly interacts with LTER Network IMs to learn about technologies, standards, and best-practices and then incorporates them into the JRN IM system; (2) focused our efforts over the past 18 months on writing and updating metadata and publishing new data to EDI, prioritizing our signature datasets (long-term, widely used in JRN or LTER network research); (3) developed the 5 IM priorities listed above; (4) created a new website data catalog that is directly synchronized with the JRN catalog at the EDI data repository; (5) updated our bibliography and personnel information and refreshed the look and feel of the JRN website; and (6) improved communication between the IM team and JRN scientists so they will be aware of, and compliant with, NSF, LTER Network, and JRN data policies. We anticipate that recent modifications to our personnel and practices, as described below, have greatly improved JRN data management and will restore our role as a leader in LTER IM in coming years.\n\n\n\nPersonnel: The JRN ‚ÄúIM team‚Äù is headed by G. Maurer. Supported at 1.0 FTE by JRN, Maurer brings a combination of ecological research experience and data management skills to the project. He leads a team comprised of a full-time computer programmer with machine learning expertise (Dr.¬†Geovany Ramirez), a full-time project manager (Dr.¬†Nina Joffe), full-time site manager John Anderson, and half-time database analyst Haneen Omari. The USDA contributions to the team include half-time statistician Darren James who assists Maurer and Omari with data quality assurance, metadata preparation, and EDI data package publication. Project manager Joffe is responsible for JRN website content and ensuring a smooth data publishing process for scientists, from study initiation to completion. USDA staff Scott Schrader and Ken Ramsey maintain servers, shared network resources, and the JRN website stack (Table 1). In addition, JRN scientists and staff contribute software tools for data analysis and visualization and share them as links or embedded apps on the JRN website.\nComputing and storage infrastructure: The JRN IT infrastructure aims to provide diverse, secure, and resilient capabilities for storing and serving information needed by JRN personnel, external collaborators, and the public. The JRN LTER is housed in Wooton Hall, headquarters of the USDA-ARS Jornada Experimental Range (JER), on the New Mexico State University (NMSU) campus. A long-standing ARS-LTER agreement allows the JER to provide and manage most of the local computing infrastructure JRN requires (Table 1), including a cluster of 5 servers with a 100TB storage block. From this cluster, a virtual Ubuntu 16.04 server hosts the JRN website, and JRN staff are provided with CIFS shares for networked file storage. Most JRN research data, IM-related metadata and tools, and staff files and documents (e.g., images, equipment manuals, procedures documents) are also stored on these network shares. Other virtual servers on the same cluster provide additional resources used by JRN, including an R Shiny application server and a MySQL database being tested for research data storage. Hardware updates and upgrades are handled by USDA-ARS staff and NMSU‚Äôs Information and Communication Technologies Office, with assistance from JRN as needed. All server and network share files are backed up on a 6-hour schedule, and full, system-wide, off-site tape backups occur monthly. Periodic technology transfers that update hardware, software, and file formats ensure long-term data protection against media or format obsolescence. The JRN IM team uses a variety of secure cloud platforms (e.g.¬†Trello, GitHub, and Zotero.org) to store and manage documentation, bibliographies, and other project data. Off-site personnel that cannot use local network shares may store files in Dropbox or Google Drive depending on project needs and institutional requirements for project members.\n\n\n\n\n\n\n\n\nLocal/remote resource\nSoftware applications\nImplemented service\n\n\n\n\nDell R710 server cluster\nCitrix Xen Hypervisor\nMiscellaneous virtual server hosting\n\n\nDell R710 server cluster\nUbuntu Linux 16.04, Apache HTTP Server, Drupal 7\nJRN website\n\n\nzotero.org, server cluster\nZotero, Javascript, Drupal\nBibliography (on JRN website)\n\n\nEDI, server cluster\nJavascript, Drupal\nData catalog (on JRN website)\n\n\nLocal storage, server cluster\nCIFS\nNetwork file storage (documents, research data, metadata)\n\n\nDropbox, Google Drive\n\nProject document storage and sharing\n\n\n\nTable 1: JRN computing resources, software, and implemented services used for Information Management.\nNetwork infrastructure: Servers and staff computers are connected to a Gigabit local area network (LAN) linked to the NMSU network (Gigabit Ethernet) through a firewall. Local networked systems and web applications are password-protected, and regular security sweeps identify security threats. The USDA Jornada field headquarters (HQ; centrally located at the LTER research site) is linked to the NMSU network via a 40 MB multi-hop, point-to-point wireless backhaul connection for large-volume data (e.g., streaming meteorological and phenocam data). Field instruments are connected via 900 MHz spread spectrum wireless radios to base stations at HQ. This network allows communication with dataloggers and other research devices to be initiated from anywhere with internet access. Wireless internet at HQ is available for JRN LTER use.\n\n\n\nThe JRN IM system consists of several interrelated components providing the critical functionality to create, manage, and distribute research data, metadata, and ancillary information. The lead IM maintains a public GitHub organization (Jornada-IM) with repositories documenting the structure, standards, and procedures of the JRN IM system, and where the IM team develops data management software tools. The important components of the JRN IM system are described below with explanations of how they are accessible to the public. The JRN IM system integrates with all stages of the DataOne data life cycle, which are identified in parentheses in section headings below.\n\n\n\nFigure 1: A simplified schematic of the JRN Information Management system. All activity and data occurring on local infrastructure (in yellow folders) is managed directly by the IM Team.\n\n\n\nData collection and quality assurance (Collect, Assure): Research data generally enters the JRN IM system by one of four routes: (1) entry of long-term datasets manually collected by the 4-person JRN field crew, (2) autonomous data collection by sensor networks and dataloggers maintained by the JRN field crew, (3) data submission by LTER investigators and students, or (4) data submission by collaborators not directly managed by JRN. For data category (1), data are collected on a schedule that varies depending on the project, and the manager Anderson is responsible for archiving raw files, data entry/transcription, and production of quality controlled files suitable for publication. To optimize efficiency, custom applications (in Excel and MATLAB) automate quality control at the time of data entry/transcription. For (2), we have adopted the MATLAB GCE Toolbox (developed at GCE LTER) for data QA/QC and publishing, and we are extending its functionality with a human-assisted ML approach developed by Anderson and Ramirez. JRN also uses the USDA-developed DIMA database installed on field tablets, which permits data quality control at the time of collection. For data category (3), data collectors are required to submit quality-assured data and metadata to the IM team within a year of research project initiation, and annually thereafter for long-term research. This also applies to graduate students receiving the JRN LTER fellowship. The IM team communicates these requirements directly to PIs and students at JRN meetings and training events. Once data and metadata is submitted, the IM team archives and applies an additional layer of quality control with custom R scripts during the data publishing phase (Fig. 1). For data category (4), collaborators not directly involved with JRN, we provide access to data standards and archival storage upon request. For example, JRN LTER has been instrumental in developing data standards in the emerging Long-Term Agroecosystems Network (Spiegal et al.¬†2019).\nData packaging and publishing (Describe, Preserve): A primary function of the JRN IM system is to create and distribute research data packages, consisting of quality-assured data and detailed metadata, to public, online data repositories (primarily EDI). There is considerable variety in data type (tabular, spatial, image, etc.), structure (variables, resolution, etc.), and source (long-term monitoring, JRN investigators, cross-site collaborators, etc.) among our data packages. All JRN data packages are therefore documented with detailed metadata by creating an XML metadata file formatted to the Ecological Metadata Language (EML) 2.2 schema. Data packages are then published to the EDI data repository through the Provenance Aware Synthesis Tracking Architecture system (PASTA+) whenever possible. Data packages held at EDI now constitute the de-facto JRN data catalog (Fig. 1), and the IM team is currently adding any missing and new packages to the repository. For data packages that are more logically archived in public repositories other than EDI (e.g, AmeriFlux), we publish a ‚Äúmetadata only‚Äù package at EDI with links to the outside data holding, allowing discovery of all JRN data packages through one catalog. We have published 117 new data packages to EDI since our 2018 panel review (the majority from our many meteorological stations), a 124% increase over the prior 4 years, and we now publish streaming data from 15 weather stations on a monthly schedule (Fig. 2).\n\n\n\nFigure 2: A plot of JRN‚Äôs PASTA+ database activity (knb-lter-jrn scope), including package creation and recurring updates, at the EDI repository since the LTER-VII proposal review. Top panel: Daily actions for all packages (spikes = meteorological data package creation/updates). Bottom panel: Cumulative actions to signature data packages (new met packages excluded). The dashed line shows our goal to update our entire signature data inventory in the first 2 years of LTER-VII.\n\n\n\nAt the time of data package publication, the IM team error-checks data, outputs the data to an accepted format, and generates an EML file. Metadata in the EML file is populated according to LTER Network best practices, using the LTER Controlled Vocabulary and Standard Units Dictionary, and according to the JRN IM team‚Äôs own metadata standards (documented and under development at the Jornada-IM GitHub organization). The IM team consults with data providers during this process to ensure that complete, accurate, and high-quality metadata are obtained. EML creation is accomplished using custom R scripts that use the EMLassemblyline and EML packages for R (developed by EDI and rOpenSci, respectively). Upon upload of EML and associated data entities to EDI, the consistency and integrity of JRN data and metadata is checked by the PASTA+ system. Following upload, data and metadata files for all data packages are archived in a secure network share in the format suggested for the EMLassemblyline package (Fig. 1).\nThe JRN website (Plan, Discover): The JRN website (https://lter.jornada.nmsu.edu) is the central means of exposing our research, education, and outreach activities to JRN scientists and staff, external collaborators, and the public in an accessible and user-friendly way. It is a clearinghouse for JRN information and the gateway for discovery of and access to JRN data. Computing resources and software powering the website are described in Table 1, and are primarily maintained by USDA staff, under the supervision of the JRN IM team and PIs. Key elements of the JRN website are:\n\nSite background and current research: The combined research history at JRN LTER and USDA JER reaches back over a century (1915), and JRN has numerous ongoing long- and short-term research and monitoring projects. This complex scientific enterprise can be challenging to communicate to new personnel, collaborators, data users, and the public. For this reason, site descriptions, research vignettes, maps, instructions for new researchers, and other interpretive materials are made available on the JRN website. These materials are periodically revised and updated to reflect new research results and priorities, or other developments.\nData catalog: The JRN data catalog can be browsed and searched with the data catalog tool on the JRN website, which links directly to package landing pages on EDI. The website data catalog queries the EDI repository using the PASTA+ API, meaning search results from the website data catalog always reflect the current JRN holdings on EDI.\nPersonnel database: The JRN personnel database is maintained on the website. Personnel records in the database store position and funding details, contact information, publication lists, and biographical details, and are updated twice yearly at a minimum. Cooperating staff and scientists in the co-located USDA-ARS Jornada Experimental Range and outside collaborators all have records in this database.\nPublication list: The IM team manages a bibliography containing all JRN publications (including peer-reviewed journal articles, book chapters, reports, and theses) using Zotero. New publications are identified through reporting by PIs or the Site Research Manager, annual reports, and Google Scholar searches. The bibliography can be browsed and searched using a tool on the JRN website.\nSynergistic activities and partnerships: The JRN LTER participates in a number of education and outreach initiatives directly and through partnerships. Web pages about workshops and courses, applications and training materials, and cooperative agreements with management agencies or community groups are either hosted directly by or linked to the JRN website.\n\nData access policies (Preserve, Discover): In adherence with the Type I data guidelines described in the LTER Network Access Policy, JRN publishes all research data no later than 2 years after collection or at the time of publication. At present, no Type II data are collected at JRN. Because the JRN LTER conducts research in areas (JER and the Chihuahuan Desert Rangeland Research Center) accessed by approved visitors, but occasionally also trespassers, detailed spatial location data for sensitive research sites are withheld from public metadata. Locations are available to researchers on request from the IM team. Most JRN data packages are published with the Creative Commons ‚ÄúCCBY‚Äù license. The JRN IM system ensures that all packages in the data catalog are publicly accessible in three locations: the JRN website data catalog, the EDI repository (in PASTA+), and the DataOne metadata aggregator through EDI‚Äôs membership.\n\n\n\nIM integration with research (Plan, Describe, Integrate, Analyze): The IM team works closely with JRN investigators, students, and collaborating scientists to ensure that their research meets data management standards and obligations. Members of the IM team consult with investigators in the early stages of research projects to design and initiate plans that ensure efficient, accurate, and complete collection of data and metadata. Upon publication, the IM team helps researchers format and revise metadata for addition to the JRN data catalog. The IM team maintains web pages in the Jornada-IM GitHub organization, targeted at JRN researchers, that distribute instructional materials, metadata templates, documentation of the JRN IM system (including this document), and offer tutorials on JRN data access and citation.\nMembers of the IM team participate in JRN research as scientists in several capacities. The lead IM is a member of the JRN Data Science team, which is developing capabilities for the proposed Data Science Integration System (DSIS) system to synthesize and harmonize datasets from different studies and locations across the Jornada Basin. The IM team works directly with investigators in the analysis and interpretation of JRN research data and contributes to JRN publications. The lead IM has latitude to collaborate with LTER Network IMs and scientists in the conception, writing, and publishing of articles in ecological informatics and cross-site synthesis.\nEducation and outreach: The lead IM strives to make sound data management a highly visible priority within the JRN LTER community, and makes every effort to provide data management services, resources, and education to our students, researchers, collaborators, and partners. The JRN IM team endeavors to raise the data literacy of these groups with several events each year. We give data management presentations and organize ‚Äúmetadata parties‚Äù at JRN events, such as the Jornada Desert Ecology Short Course, and at invited opportunities with JRN-affiliated lab and student groups at NMSU and the University of Texas-El Paso. A new ‚ÄúData Bounty Hunters‚Äù program will begin in 2020. Instructional materials on metadata, JRN data access, and data citation are being written to complement all these events. The IM team communicates regularly with investigators and graduate students to track research progress, request data and metadata submission, and raise awareness of current and developing LTER Network data management practices and expectations. The co-located USDA-ARS Jornada Experimental Range supports several applied science and informatics projects (Landscape Data Commons, for example) where future collaborations will enable shared development of informatics tools, best practices, and educational curricula of interest to JRN and the LTER Network. Finally, the IM Team is planning new initiatives with JRN‚Äôs outreach partners, including the Asombro Institute for Science Education. These include archiving student research data and contributing to development of data literacy curricula for primary and secondary school students and teachers.\nNetwork participation: Lead IM Maurer actively contributes to the LTER Network‚Äôs IM activities in several capacities. Presently, he participates in the LTER IM ‚ÄúNon-tabular data‚Äù working group developing best practices for publishing data packages with non-standard data types, including UAV image and hyperspectral data, photographic datasets, ecological models, and genomic data. Maurer has recently begun working with EDI software developers with the goal of contributing bug fixes and improvements to the EMLassemblyline R package. The JRN IM team also participates in a southwest U.S. regional group of LTER sites (JRN, SEV, CAP, and MCM) with nascent plans for regional data management workshops and informatics initiatives slated to begin in August 2020. Future JRN IM work will be presented at conferences, training sessions, the annual IMC meeting, and in peer-reviewed journal articles. The expanded GCE Toolbox using machine learning to QA/QC streaming met station data will be made available to other sites in the near future.\n\n\n\nMilestones in the current funding cycle: Since the probationary LTER award in 2018, JRN has focused its efforts on developing new IM practices compliant with NSF and LTER standards, and on updating the JRN data catalog. Milestones we have reached in the past 18 months include:\n\nDevelopment of new data and metadata content and formatting standards for all JRN data packages.\nPrioritization of JRN data packages for publication to EDI based on three classes: long-term signature, long-term, and short-term.\nUpdated metadata and data (to 2019) for all of JRN‚Äôs long-term signature packages on EDI, and ensured they are consistent with our newly developed standards.\nReleased a major revision of our website with updates to interpretive material, the data catalog, and the JRN bibliography.\n\nFuture initiatives: The JRN IM system has become more robust and effective over the past 18 months, approaching our goal that information management at JRN must meet or exceed all LTER Network standards and expectations. In addition to implementing the planned data literacy education and outreach initiatives outlined earlier, the lead IM is working to identify further improvements to the IM system itself. Planned improvements during the next phase of LTER-VII include:\n\nIntegration of research and data management forms and tracking with the JRN website.\nUpdating data and metadata in completed, short-term, student, and other non-signature data packages that currently have lower priority in the JRN data catalog.\nDevelopment of a new metadata database using the LTER-core-metabase schema currently being developed by LTER IMs.\nCreation of new workflows and data management tools to assist in the analysis and publication of our growing catalog of ecological imagery data from UAVs, phenocams, and other platforms.\nContinued development of the data management and analysis capabilities needed for DSIS, including aggregating and harmonizing suites of ecological data, further enhancement and standardization of project metadata, databasing of tabular research data, and development of analytical applications using open-source tools like R and Python."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER7.html#introduction",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER7.html#introduction",
    "title": "Data Management Plan",
    "section": "",
    "text": "The core goals of the Information Management (IM) system at the Jornada Basin LTER (JRN) are to support and enhance investigations and data collection, and to make data and other scientific products openly accessible to the science community, resource managers, policy makers, and the public. We are meeting these goals by addressing five IM priorities: (1) design and implement efficient systems to collect, quality-assure, document, and archive research data; (2) annotate research data with complete, standardized metadata; (3) timely publication of data and metadata in accepted research data repositories; (4) promote and facilitate discovery and re-use of JRN research data; and (5) advance sound data management and sharing practices at JRN through leadership and educational activities. The lead Information Manager and other staff use diverse technologies to advance these priorities and hold monthly meetings with JRN PIs to allow oversight of IM activities and promote the development of new goals and procedures.\nOwing to IM deficiencies identified in the renewal proposal review, NSF granted JRN a probationary 2-year LTER award (instead of a full 6-year award) in 2018. A key concern was that JRN data packages were not routinely entered and updated in the Environmental Data Initiative‚Äôs data repository (EDI). In response, we: (1) hired a new lead IM (Dr.¬†Greg Maurer, started May 1, 2019), who regularly interacts with LTER Network IMs to learn about technologies, standards, and best-practices and then incorporates them into the JRN IM system; (2) focused our efforts over the past 18 months on writing and updating metadata and publishing new data to EDI, prioritizing our signature datasets (long-term, widely used in JRN or LTER network research); (3) developed the 5 IM priorities listed above; (4) created a new website data catalog that is directly synchronized with the JRN catalog at the EDI data repository; (5) updated our bibliography and personnel information and refreshed the look and feel of the JRN website; and (6) improved communication between the IM team and JRN scientists so they will be aware of, and compliant with, NSF, LTER Network, and JRN data policies. We anticipate that recent modifications to our personnel and practices, as described below, have greatly improved JRN data management and will restore our role as a leader in LTER IM in coming years."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER7.html#im-resources",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER7.html#im-resources",
    "title": "Data Management Plan",
    "section": "",
    "text": "Personnel: The JRN ‚ÄúIM team‚Äù is headed by G. Maurer. Supported at 1.0 FTE by JRN, Maurer brings a combination of ecological research experience and data management skills to the project. He leads a team comprised of a full-time computer programmer with machine learning expertise (Dr.¬†Geovany Ramirez), a full-time project manager (Dr.¬†Nina Joffe), full-time site manager John Anderson, and half-time database analyst Haneen Omari. The USDA contributions to the team include half-time statistician Darren James who assists Maurer and Omari with data quality assurance, metadata preparation, and EDI data package publication. Project manager Joffe is responsible for JRN website content and ensuring a smooth data publishing process for scientists, from study initiation to completion. USDA staff Scott Schrader and Ken Ramsey maintain servers, shared network resources, and the JRN website stack (Table 1). In addition, JRN scientists and staff contribute software tools for data analysis and visualization and share them as links or embedded apps on the JRN website.\nComputing and storage infrastructure: The JRN IT infrastructure aims to provide diverse, secure, and resilient capabilities for storing and serving information needed by JRN personnel, external collaborators, and the public. The JRN LTER is housed in Wooton Hall, headquarters of the USDA-ARS Jornada Experimental Range (JER), on the New Mexico State University (NMSU) campus. A long-standing ARS-LTER agreement allows the JER to provide and manage most of the local computing infrastructure JRN requires (Table 1), including a cluster of 5 servers with a 100TB storage block. From this cluster, a virtual Ubuntu 16.04 server hosts the JRN website, and JRN staff are provided with CIFS shares for networked file storage. Most JRN research data, IM-related metadata and tools, and staff files and documents (e.g., images, equipment manuals, procedures documents) are also stored on these network shares. Other virtual servers on the same cluster provide additional resources used by JRN, including an R Shiny application server and a MySQL database being tested for research data storage. Hardware updates and upgrades are handled by USDA-ARS staff and NMSU‚Äôs Information and Communication Technologies Office, with assistance from JRN as needed. All server and network share files are backed up on a 6-hour schedule, and full, system-wide, off-site tape backups occur monthly. Periodic technology transfers that update hardware, software, and file formats ensure long-term data protection against media or format obsolescence. The JRN IM team uses a variety of secure cloud platforms (e.g.¬†Trello, GitHub, and Zotero.org) to store and manage documentation, bibliographies, and other project data. Off-site personnel that cannot use local network shares may store files in Dropbox or Google Drive depending on project needs and institutional requirements for project members.\n\n\n\n\n\n\n\n\nLocal/remote resource\nSoftware applications\nImplemented service\n\n\n\n\nDell R710 server cluster\nCitrix Xen Hypervisor\nMiscellaneous virtual server hosting\n\n\nDell R710 server cluster\nUbuntu Linux 16.04, Apache HTTP Server, Drupal 7\nJRN website\n\n\nzotero.org, server cluster\nZotero, Javascript, Drupal\nBibliography (on JRN website)\n\n\nEDI, server cluster\nJavascript, Drupal\nData catalog (on JRN website)\n\n\nLocal storage, server cluster\nCIFS\nNetwork file storage (documents, research data, metadata)\n\n\nDropbox, Google Drive\n\nProject document storage and sharing\n\n\n\nTable 1: JRN computing resources, software, and implemented services used for Information Management.\nNetwork infrastructure: Servers and staff computers are connected to a Gigabit local area network (LAN) linked to the NMSU network (Gigabit Ethernet) through a firewall. Local networked systems and web applications are password-protected, and regular security sweeps identify security threats. The USDA Jornada field headquarters (HQ; centrally located at the LTER research site) is linked to the NMSU network via a 40 MB multi-hop, point-to-point wireless backhaul connection for large-volume data (e.g., streaming meteorological and phenocam data). Field instruments are connected via 900 MHz spread spectrum wireless radios to base stations at HQ. This network allows communication with dataloggers and other research devices to be initiated from anywhere with internet access. Wireless internet at HQ is available for JRN LTER use."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER7.html#elements-of-the-jrn-im-system",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER7.html#elements-of-the-jrn-im-system",
    "title": "Data Management Plan",
    "section": "",
    "text": "The JRN IM system consists of several interrelated components providing the critical functionality to create, manage, and distribute research data, metadata, and ancillary information. The lead IM maintains a public GitHub organization (Jornada-IM) with repositories documenting the structure, standards, and procedures of the JRN IM system, and where the IM team develops data management software tools. The important components of the JRN IM system are described below with explanations of how they are accessible to the public. The JRN IM system integrates with all stages of the DataOne data life cycle, which are identified in parentheses in section headings below.\n\n\n\nFigure 1: A simplified schematic of the JRN Information Management system. All activity and data occurring on local infrastructure (in yellow folders) is managed directly by the IM Team.\n\n\n\nData collection and quality assurance (Collect, Assure): Research data generally enters the JRN IM system by one of four routes: (1) entry of long-term datasets manually collected by the 4-person JRN field crew, (2) autonomous data collection by sensor networks and dataloggers maintained by the JRN field crew, (3) data submission by LTER investigators and students, or (4) data submission by collaborators not directly managed by JRN. For data category (1), data are collected on a schedule that varies depending on the project, and the manager Anderson is responsible for archiving raw files, data entry/transcription, and production of quality controlled files suitable for publication. To optimize efficiency, custom applications (in Excel and MATLAB) automate quality control at the time of data entry/transcription. For (2), we have adopted the MATLAB GCE Toolbox (developed at GCE LTER) for data QA/QC and publishing, and we are extending its functionality with a human-assisted ML approach developed by Anderson and Ramirez. JRN also uses the USDA-developed DIMA database installed on field tablets, which permits data quality control at the time of collection. For data category (3), data collectors are required to submit quality-assured data and metadata to the IM team within a year of research project initiation, and annually thereafter for long-term research. This also applies to graduate students receiving the JRN LTER fellowship. The IM team communicates these requirements directly to PIs and students at JRN meetings and training events. Once data and metadata is submitted, the IM team archives and applies an additional layer of quality control with custom R scripts during the data publishing phase (Fig. 1). For data category (4), collaborators not directly involved with JRN, we provide access to data standards and archival storage upon request. For example, JRN LTER has been instrumental in developing data standards in the emerging Long-Term Agroecosystems Network (Spiegal et al.¬†2019).\nData packaging and publishing (Describe, Preserve): A primary function of the JRN IM system is to create and distribute research data packages, consisting of quality-assured data and detailed metadata, to public, online data repositories (primarily EDI). There is considerable variety in data type (tabular, spatial, image, etc.), structure (variables, resolution, etc.), and source (long-term monitoring, JRN investigators, cross-site collaborators, etc.) among our data packages. All JRN data packages are therefore documented with detailed metadata by creating an XML metadata file formatted to the Ecological Metadata Language (EML) 2.2 schema. Data packages are then published to the EDI data repository through the Provenance Aware Synthesis Tracking Architecture system (PASTA+) whenever possible. Data packages held at EDI now constitute the de-facto JRN data catalog (Fig. 1), and the IM team is currently adding any missing and new packages to the repository. For data packages that are more logically archived in public repositories other than EDI (e.g, AmeriFlux), we publish a ‚Äúmetadata only‚Äù package at EDI with links to the outside data holding, allowing discovery of all JRN data packages through one catalog. We have published 117 new data packages to EDI since our 2018 panel review (the majority from our many meteorological stations), a 124% increase over the prior 4 years, and we now publish streaming data from 15 weather stations on a monthly schedule (Fig. 2).\n\n\n\nFigure 2: A plot of JRN‚Äôs PASTA+ database activity (knb-lter-jrn scope), including package creation and recurring updates, at the EDI repository since the LTER-VII proposal review. Top panel: Daily actions for all packages (spikes = meteorological data package creation/updates). Bottom panel: Cumulative actions to signature data packages (new met packages excluded). The dashed line shows our goal to update our entire signature data inventory in the first 2 years of LTER-VII.\n\n\n\nAt the time of data package publication, the IM team error-checks data, outputs the data to an accepted format, and generates an EML file. Metadata in the EML file is populated according to LTER Network best practices, using the LTER Controlled Vocabulary and Standard Units Dictionary, and according to the JRN IM team‚Äôs own metadata standards (documented and under development at the Jornada-IM GitHub organization). The IM team consults with data providers during this process to ensure that complete, accurate, and high-quality metadata are obtained. EML creation is accomplished using custom R scripts that use the EMLassemblyline and EML packages for R (developed by EDI and rOpenSci, respectively). Upon upload of EML and associated data entities to EDI, the consistency and integrity of JRN data and metadata is checked by the PASTA+ system. Following upload, data and metadata files for all data packages are archived in a secure network share in the format suggested for the EMLassemblyline package (Fig. 1).\nThe JRN website (Plan, Discover): The JRN website (https://lter.jornada.nmsu.edu) is the central means of exposing our research, education, and outreach activities to JRN scientists and staff, external collaborators, and the public in an accessible and user-friendly way. It is a clearinghouse for JRN information and the gateway for discovery of and access to JRN data. Computing resources and software powering the website are described in Table 1, and are primarily maintained by USDA staff, under the supervision of the JRN IM team and PIs. Key elements of the JRN website are:\n\nSite background and current research: The combined research history at JRN LTER and USDA JER reaches back over a century (1915), and JRN has numerous ongoing long- and short-term research and monitoring projects. This complex scientific enterprise can be challenging to communicate to new personnel, collaborators, data users, and the public. For this reason, site descriptions, research vignettes, maps, instructions for new researchers, and other interpretive materials are made available on the JRN website. These materials are periodically revised and updated to reflect new research results and priorities, or other developments.\nData catalog: The JRN data catalog can be browsed and searched with the data catalog tool on the JRN website, which links directly to package landing pages on EDI. The website data catalog queries the EDI repository using the PASTA+ API, meaning search results from the website data catalog always reflect the current JRN holdings on EDI.\nPersonnel database: The JRN personnel database is maintained on the website. Personnel records in the database store position and funding details, contact information, publication lists, and biographical details, and are updated twice yearly at a minimum. Cooperating staff and scientists in the co-located USDA-ARS Jornada Experimental Range and outside collaborators all have records in this database.\nPublication list: The IM team manages a bibliography containing all JRN publications (including peer-reviewed journal articles, book chapters, reports, and theses) using Zotero. New publications are identified through reporting by PIs or the Site Research Manager, annual reports, and Google Scholar searches. The bibliography can be browsed and searched using a tool on the JRN website.\nSynergistic activities and partnerships: The JRN LTER participates in a number of education and outreach initiatives directly and through partnerships. Web pages about workshops and courses, applications and training materials, and cooperative agreements with management agencies or community groups are either hosted directly by or linked to the JRN website.\n\nData access policies (Preserve, Discover): In adherence with the Type I data guidelines described in the LTER Network Access Policy, JRN publishes all research data no later than 2 years after collection or at the time of publication. At present, no Type II data are collected at JRN. Because the JRN LTER conducts research in areas (JER and the Chihuahuan Desert Rangeland Research Center) accessed by approved visitors, but occasionally also trespassers, detailed spatial location data for sensitive research sites are withheld from public metadata. Locations are available to researchers on request from the IM team. Most JRN data packages are published with the Creative Commons ‚ÄúCCBY‚Äù license. The JRN IM system ensures that all packages in the data catalog are publicly accessible in three locations: the JRN website data catalog, the EDI repository (in PASTA+), and the DataOne metadata aggregator through EDI‚Äôs membership."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER7.html#additional-im-activities",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER7.html#additional-im-activities",
    "title": "Data Management Plan",
    "section": "",
    "text": "IM integration with research (Plan, Describe, Integrate, Analyze): The IM team works closely with JRN investigators, students, and collaborating scientists to ensure that their research meets data management standards and obligations. Members of the IM team consult with investigators in the early stages of research projects to design and initiate plans that ensure efficient, accurate, and complete collection of data and metadata. Upon publication, the IM team helps researchers format and revise metadata for addition to the JRN data catalog. The IM team maintains web pages in the Jornada-IM GitHub organization, targeted at JRN researchers, that distribute instructional materials, metadata templates, documentation of the JRN IM system (including this document), and offer tutorials on JRN data access and citation.\nMembers of the IM team participate in JRN research as scientists in several capacities. The lead IM is a member of the JRN Data Science team, which is developing capabilities for the proposed Data Science Integration System (DSIS) system to synthesize and harmonize datasets from different studies and locations across the Jornada Basin. The IM team works directly with investigators in the analysis and interpretation of JRN research data and contributes to JRN publications. The lead IM has latitude to collaborate with LTER Network IMs and scientists in the conception, writing, and publishing of articles in ecological informatics and cross-site synthesis.\nEducation and outreach: The lead IM strives to make sound data management a highly visible priority within the JRN LTER community, and makes every effort to provide data management services, resources, and education to our students, researchers, collaborators, and partners. The JRN IM team endeavors to raise the data literacy of these groups with several events each year. We give data management presentations and organize ‚Äúmetadata parties‚Äù at JRN events, such as the Jornada Desert Ecology Short Course, and at invited opportunities with JRN-affiliated lab and student groups at NMSU and the University of Texas-El Paso. A new ‚ÄúData Bounty Hunters‚Äù program will begin in 2020. Instructional materials on metadata, JRN data access, and data citation are being written to complement all these events. The IM team communicates regularly with investigators and graduate students to track research progress, request data and metadata submission, and raise awareness of current and developing LTER Network data management practices and expectations. The co-located USDA-ARS Jornada Experimental Range supports several applied science and informatics projects (Landscape Data Commons, for example) where future collaborations will enable shared development of informatics tools, best practices, and educational curricula of interest to JRN and the LTER Network. Finally, the IM Team is planning new initiatives with JRN‚Äôs outreach partners, including the Asombro Institute for Science Education. These include archiving student research data and contributing to development of data literacy curricula for primary and secondary school students and teachers.\nNetwork participation: Lead IM Maurer actively contributes to the LTER Network‚Äôs IM activities in several capacities. Presently, he participates in the LTER IM ‚ÄúNon-tabular data‚Äù working group developing best practices for publishing data packages with non-standard data types, including UAV image and hyperspectral data, photographic datasets, ecological models, and genomic data. Maurer has recently begun working with EDI software developers with the goal of contributing bug fixes and improvements to the EMLassemblyline R package. The JRN IM team also participates in a southwest U.S. regional group of LTER sites (JRN, SEV, CAP, and MCM) with nascent plans for regional data management workshops and informatics initiatives slated to begin in August 2020. Future JRN IM work will be presented at conferences, training sessions, the annual IMC meeting, and in peer-reviewed journal articles. The expanded GCE Toolbox using machine learning to QA/QC streaming met station data will be made available to other sites in the near future."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER7.html#recent-accomplishments-and-future-initiatives",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER7.html#recent-accomplishments-and-future-initiatives",
    "title": "Data Management Plan",
    "section": "",
    "text": "Milestones in the current funding cycle: Since the probationary LTER award in 2018, JRN has focused its efforts on developing new IM practices compliant with NSF and LTER standards, and on updating the JRN data catalog. Milestones we have reached in the past 18 months include:\n\nDevelopment of new data and metadata content and formatting standards for all JRN data packages.\nPrioritization of JRN data packages for publication to EDI based on three classes: long-term signature, long-term, and short-term.\nUpdated metadata and data (to 2019) for all of JRN‚Äôs long-term signature packages on EDI, and ensured they are consistent with our newly developed standards.\nReleased a major revision of our website with updates to interpretive material, the data catalog, and the JRN bibliography.\n\nFuture initiatives: The JRN IM system has become more robust and effective over the past 18 months, approaching our goal that information management at JRN must meet or exceed all LTER Network standards and expectations. In addition to implementing the planned data literacy education and outreach initiatives outlined earlier, the lead IM is working to identify further improvements to the IM system itself. Planned improvements during the next phase of LTER-VII include:\n\nIntegration of research and data management forms and tracking with the JRN website.\nUpdating data and metadata in completed, short-term, student, and other non-signature data packages that currently have lower priority in the JRN data catalog.\nDevelopment of a new metadata database using the LTER-core-metabase schema currently being developed by LTER IMs.\nCreation of new workflows and data management tools to assist in the analysis and publication of our growing catalog of ecological imagery data from UAVs, phenocams, and other platforms.\nContinued development of the data management and analysis capabilities needed for DSIS, including aggregating and harmonizing suites of ecological data, further enhancement and standardization of project metadata, databasing of tabular research data, and development of analytical applications using open-source tools like R and Python."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER8.html",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER8.html",
    "title": "Data Management Plan for JRN LTER-8",
    "section": "",
    "text": "version 0.4\n\n\nThe Jornada Basin LTER program (JRN) supports an effective and well-integrated information management (IM) program and shares the LTER Network view that published datasets are first-class products of research and an opportunity for outreach and education. The JRN Information Management (IM) system reliably performs a full range of essential data management functions to make research data and other information produced by the JRN program findable, accessible, interoperable, and re-usable (FAIR, Wilkinson et al.¬†2016). The team that designs and operates this system is guided by three core priorities.\n\nContribute to high quality, impactful ecology research at all stages of the data life cycle\nOversee, or directly handle, publication of all Jornada datasets\nAct as a source of data-related leadership, education, and outreach\n\nThe JRN IM team approaches each of these priorities with a philosophy of openness to diverse stakeholders, including scientists, resource managers, students, & the public, and a commitment to the principles of open scientific research. In this Data Management Plan, we review recent progress in JRN IM, and outline the strategy for managing and publishing JRN research data from 2025 to 2030.\n\n\n\nPersonnel: The JRN IM team is headed by Dr.¬†Gregory Maurer, supported at 0.5 FTE by JRN. He leads a team comprised of a part-time computer programmer and part-time undergraduate assistants who contribute to data QA/QC, website content, and communications. The IM team works closely with JRN‚Äôs full-time site manager and program coordinator, and also collaborates closely with USDA data managers, including statistician Darren James, and local computing and network infrastructure managers Scott Schrader and Ken Ramsey. Maurer meets at least monthly with the JRN leadership team to align IM activities with research priorities, convey updates, and take feedback on data management standards and procedures.\nComputing and storage infrastructure: The JRN IM system is built on multiple technologies and infrastructure resources that provide secure, resilient computing and storage capabilities for JRN personnel, external collaborators, and the public. Most members of the JRN IM team have offices in Wooton Hall, headquarters of the USDA-ARS Jornada Experimental Range (JER), on New Mexico State University (NMSU) campus. A long-standing ARS-LTER agreement allows the JER to provide and manage some of the computing infrastructure that JRN requires (Table 1), including a server cluster with a 100TB storage block from which JRN staff are provided with networked file storage shares. Research data, IM-related metadata and tools, and staff files and documents (e.g., images, equipment manuals, procedures documents) are stored on these shares. Most other JRN IM infrastructure has transitioned to cloud-based systems in the last four years (Table 1) to reduce physical infrastructure maintenance demands and increase reliability and uptime. Linux virtual machines and S3-compatible object stores at DigitalOcean.com host databases with research metadata and other information (PostgreSQL 12), web-accessible storage for data entities, and full offsite backups of local Jornada file storage. The JRN website is built with WordPress and has several associated Javascript data catalog and bibliography applications, all of which are hosted at WPengine.com. Data catalogs and bibliography apps rely on API access to data stores at the Environmental Data Initiative (EDI) repository, Zotero.org, and NMSU‚Äôs ArcGIS Online instance. The JRN website‚Äôs interactive data viewer is hosted at the USDA-ARS-supported Shinyapps.io account. All cloud-based systems have a minimum of nightly backups with distributed storage and rollback ability. The JRN IM team backs up all shared local files nightly to an in-house device and the DigitalOcean S3 bucket, which is in addition to weekly, off-site tape-drive backups of the same data performed by USDA-ARS staff. Technology transfers update hardware, software, and file formats on a 3-5 year cycle to ensure long-term data protection against media or format obsolescence. Depending on project needs and institutional requirements, the IM team and researchers use a variety of secure cloud platforms (e.g.¬†Trello, GitHub, Dropbox or Google Drive) for online collaboration and storage of documentation, code, and other project information.\n\n\n\n\n\n\n\n\nImplemented service\nLocal/remote infrastructure\nSoftware\n\n\n\n\nNetworked file storage on NMSU campus\n100TB local storage block\nCIFS\n\n\nLTER-core-metabase metadata database\nDigitalOcean.com VM\nUbuntu Linux 20.04, PostgreSQL 12.16\n\n\nWeb-accessible data storage, offsite backups\nDigitalOcean.com Spaces\nS3-compatible object store\n\n\nJRN website and associated app hosting\nWPengine.com\nWordpress 6\n\n\nEDI data catalog app (JRN website)\nportal.edirepository.org\nPASTA+ API, Javascript\n\n\nBibliography, non-EDI data catalog apps (JRN website)\nZotero.org\nZotero API, Javascript\n\n\nInteractive data viewer (JRN website)\nShinyapps.io\nR Shiny (Javascript app builder)\n\n\nDocument storage/sharing for remote collaboration\nDropbox, Google Drive, GitHub\n\n\n\n\nTable 1: The information technology services used by JRN, along with the associated local or remote infrastructure and softwares responsible for implementing them.\nNetwork infrastructure: Servers and staff computers at Wooton Hall are connected to a Gigabit local area network (LAN) linked to the NMSU network (Gigabit Ethernet) through a firewall. Local networked systems and web applications are password-protected, and regular security sweeps identify security threats. The USDA Jornada field headquarters (HQ; centrally located at the LTER research site) is linked to the NMSU network via a 40 MB multi-hop, point-to-point wireless backhaul connection that can accommodate large-volume data. Field instruments are connected via spread spectrum wireless radios to base stations and the internet at HQ. Wireless internet at HQ is available for JRN LTER use.\n\n\n\nJornada data management practices must accommodate diverse research activities and data products, ranging from tabular field data, to ground-based and airborne imagery, to ecological model outputs, to data from specimen and sample collections. The JRN IM system therefore uses several infrastructure components and procedures to create, manage, and distribute research data and other information in a modular way. Wherever possible the JRN IM team uses open-source tools and community standards. All documentation for the system is available in the group‚Äôs public GitHub organization (https://github.com/jornada-im), along with instructional materials for data-related education and outreach. Essential functions that the IM system delivers, with relevant components and processes, are described below. Stages of the DataONE data life cycle are identified in parentheses after section headings.\n\n\n\nFigure 1: A simplified schematic of the JRN Information Management system. Handling of a contributed JRN research dataset is depicted on the left, with infrastructure components (local and cloud-based) to the right. Labeled arrows depict data management processes, including a) the dataset submission, review, and revision process between IMs and researchers, b) data entry and backup to local and cloud infrastructure, c) dataset publication to EDI, d) cloud platform (EDI, shinyapps.io, ArcGIS Online, Zotero.org) API service calls updating the JRN website, and e) data and application updates to cloud platform services. Dashed arrows involve scripting and automation. Image credit xkcd.com.\n\n\n\n\n\nFigure 1: A simplified schematic of the JRN Information Management system. A research dataset contributed to the IM team is depicted on the left, with infrastructure components (local and cloud-based) to the right. Labeled arrows represent data management processes, including a) dataset submission, review, and revision in coordination with researchers, b) data entry and backup to local and cloud infrastructure, c) dataset publication to EDI, d) cloud platform (EDI, shinyapps.io, ArcGIS Online, Zotero.org) API service calls updating the JRN website, and e) data and application updates to cloud platform services. All dashed arrows involve some scripting and automation. Image credit xkcd.com.\n\n\n\nData collection and quality assurance (Collect, Assure): The IM team carefully tracks the status of Jornada research projects to ensure that collected data receive thorough quality checks before being published. Most data products from JRN projects are tabular in nature, and there are three primary entry points for this data into the JRN IM system: (1) collection of long-term datasets by the 3-person JRN field crew and site manager Anderson, (2) autonomous data collection by sensor networks and dataloggers, and (3) data submission by LTER investigators, students, and collaborators. For data entry point (1), field data collection schedules vary depending on the project, and site manager Anderson is responsible for archiving raw files and managing data entry/transcription and validation procedures. Anderson works closely with the rest of the IM team to quality assure and check (QA/QC) new data and produce files suitable for publication on an annual basis. To optimize efficiency, the IM team has developed custom workflows (in R, Python, Matlab, or Excel) to assist with QA/QC and generate output files. For entry point (2) we use the MATLAB GCE Toolbox (developed at GCE LTER) for data QA/QC, and have extended its functionality to allow rapid data flagging and publication to EDI using software developed by Ramirez and Anderson. For entry point (3), students and investigators QA/QC their own data and submit it with appropriate metadata to the IM team on a timeframe matching JRN and LTER data access policies (see below). Once data and metadata are submitted to the IM team, an additional layer of QA/QC and standardization is applied through database validation and custom R scripts (Fig. 1) during the data publication phase.\nThere are several classes of specialized JRN data products, including large datasets and non-tabular formats, that require a flexible approach to quality assurance. Biological specimens and physical samples destined for scientific collections are not assessed or otherwise handled directly by the IM team. Sequencing and genomic research generates datasets that are best assessed by those trained in bioinformatics. JRN modeling activities generate rapidly evolving code and parameter sets, and voluminous output/simulation data. Similarly, large collections of ground-based or airborne imagery are generated by multiple JRN research efforts. In each of these cases the JRN IM team has limited capacity to directly QA/QC the data. Instead, the focus is on training and coordination with the responsible researchers to ensure data quality and security, and collection of appropriate, descriptive metadata.\nData packaging and publishing (Describe, Preserve): To meet the FAIR data criteria, JRN strives to publish quality-assured data accompanied by rich, detailed metadata. Creating and publishing new datasets begins with submission of metadata using EDI‚Äôs ezEML tool, or a metadata template created by the IM team (MS Word or Excel formats). The IM team consults closely with researchers, students, and staff to determine what constitutes a useful dataset and how to describe one with metadata. Upon submission, the IM team stores and manages metadata for all tabular data products in a relational database following the LTER-core-metabase schema (metabase hereafter) which is maintained by a working group of the LTER Network Information Management Committee (IMC). This system validates and enforces standards, such as use of the LTER Controlled Vocabulary and Standard Units Dictionary, for incoming metadata. JRN also uses its own set of metadata standards and controlled vocabularies developed in consultation with Jornada researchers.\nThe JRN IM team publishes datasets in community-accepted online data repositories, with most going to the EDI data repository, which is closely affiliated with the LTER Network and focuses on metadata standards and data re-use. Before publication, the IM team error-checks and formats data files for usability, then uses an R-based workflow (MetaEgress and jerald packages) to extract metadata from metabase and generate an XML file formatted to the Ecological Metadata Language (EML) 2.2 standard. Data and EML files are then published together in EDI‚Äôs Provenance Aware Synthesis Tracking Architecture system (PASTA+). The consistency and integrity of all data and metadata is checked again by the PASTA+ system upon entering the repository. Datasets held at EDI constitute the primary JRN data catalog (Fig. 1), but some JRN data products are published elsewhere.\nSpecialized data products often have unique, community-standard data formats and metadata, and may benefit from alternative repository systems and publication methods. The IM team encourages and facilitates publication to non-EDI data repositories when logical to do so, and there are significant JRN data holdings in NCBI databases (sequencing and genomic data), AmeriFlux (flux towers), and the Phenocam network. Citation metadata for products in these repositories are entered into a Zotero library and listed in JRN‚Äôs non-EDI data catalog. In JRN-8 the IM team will begin placing new high-volume datasets (UAS imagery, acoustic monitoring data, model training data) into offline storage and making metadata records available in EDI. In all these cases the JRN IM team prioritizes providing high-quality metadata to allow others to discover the data, wherever it may reside, and assess its quality and fitness for use.\nFor specimens and samples collected during JRN research (a new data management focus), the IM team collaborates with investigators to identify suitable partner museums or natural history collections, assemble appropriate metadata, and then accession the physical items into the collection, and metadata into an accessible database (e.g.¬†Arctos, Symbiota). Plant and vertebrate voucher specimens are currently sent to the NMSU Herbaria and NMSU Wildlife Museums, respectively, and less-frequently collected specimens, like invertebrates, have been accessioned into a range of other collections in the past. Decades of Jornada soil survey and pedology samples have been archived at the NRCS National Soil Archive. When accessioning specimens and samples into established collections is not possible, the JRN IM team ensures stable local storage, catalogs all appropriate metadata, and makes the collection accessible on the JRN website. Some physical samples, including aeolian dust, atmospheric deposition, and plant tissue samples, are already handled this way. In recent years at JRN, environmental samples like soils, biocrusts, tissues, fecal pellets, and DNA extracts are being collected for metabarcoding, metagenomics, and other sequencing-based methods of investigation. Most of these are currently archived in investigator or departmental laboratory facilities (-80 freezers). In JRN-8, the IM team is proposing new protocols to handle these samples and associated data; see item 4 under ‚ÄúFuture initiatives‚Äù below.\n\n\n\nFigure 2: A plot of JRN‚Äôs PASTA+ database activity (knb-lter-jrn scope) at the EDI repository since the 2020 JRN-8 proposal submission. Panel A: Cumulative dataset creation and update events. Panel B: Daily data downloads for JRN datasets. Known robots have been removed.\n\n\n\n\n\nFigure 2: A plot of JRN‚Äôs PASTA+ database activity (knb-lter-jrn scope) at the EDI repository since the 2020 JRN-8 proposal submission. Panel A: Cumulative dataset creation and update events. Panel B: Daily data downloads for JRN datasets. Known robots have been removed. \n\n\n\nData archiving and access policies (Preserve, Discover): In adherence with the Type I data guidelines described in the LTER Network Data Access Policy, JRN strives to publish all research data no more than 2 years after collection or at the time of journal article publication. Long-term core research datasets are prioritized highest for publication within this 2 year period, while student thesis data receive lower publication priority as students finish, and datasets from early, previously unpublished JRN studies are published as time allows. To ensure compliance with this policy, JRN strongly encourages timely submission and archiving of research data from all supported projects. Investigators and students, particularly those receiving JRN graduate fellowships or other funds, are required to submit data to the IM team within a year of research project initiation, and annually thereafter for long-term research. The IM team regularly communicates these requirements directly to PIs and students at JRN meetings and training events. At present, no Type II data are collected at JRN.\nData published in the primary JRN data catalog are publicly accessible in three locations: the JRN website, EDI, and the DataONE metadata aggregator through EDI‚Äôs membership. Almost all JRN datasets are published with the Creative Commons ‚ÄúCCBY‚Äù or ‚ÄúCC0‚Äù license, with minor exceptions for JRN data published in non-EDI repositories (e.g.¬†NCBI). Detailed spatial data for research sites and instrumentation in areas accessible to the public (JER and the Chihuahuan Desert Rangeland Research Center) are withheld from public metadata but are available to researchers upon request.\nThe JRN website (Plan, Discover): The JRN website (https://lter.jornada.nmsu.edu) is the central means of exposing all aspects of research, education, and outreach activities in an accessible and user-friendly way. It conveys this information through a mix of static and interactive pages featuring site and program descriptions, blog posts, maps, research vignettes, and other materials. Website information is updated regularly and designed for effective communication with JRN scientists, staff, external collaborators, and the public.\nThe JRN website has two main data-related functions. First, it directly communicates important information about collecting and sharing data to JRN researchers and staff. The ‚ÄúFor Researchers‚Äù menu covers important topics such as (a) procedures for initiating new research, (b) site and field safety information, (c) conduct and inclusive research expectations, (d) incident reporting, and (e) expectations and procedures for contributing Jornada data, specimens, and samples. The IM team ensures that this content is accessible, clear, and actionable. Second, the website is the gateway for discovery and access to JRN data. The website data catalog is multi-faceted and includes capable browsing and search tools. The primary website data catalog queries the EDI repository using the PASTA+ API and returns results that link directly to dataset landing pages on EDI, meaning that the data catalog always reflects current JRN holdings on EDI. Other facets of the data catalog allow discovery of non-EDI datasets, spatial data, biological specimens and physical samples, and data available from JRN‚Äôs non-LTER research partners.\nAccess to JRN publication and personnel listings is provided via website applications as well. For publications, an LTER-community maintained javascript application provides access to a Zotero.org-backed JRN bibliography of peer-reviewed journal articles, book chapters, reports, and theses. Current JRN personnel are featured on the website using a WordPress plugin, which the IM team populates from an extensive personnel database that reaches back to the beginning of the program.\n\n\n\nIM integration with research (Plan, Describe, Integrate, Analyze): The IM team is composed of experienced ecologists, statisticians, and computer scientists (and students in these fields) who contribute to JRN research in a range of scientific capacities. They work closely with Jornada investigators to ensure that research projects are soundly designed, address high-priority JRN research objectives, and meet all open science and data management standards and obligations. For new research, IM involvement typically begins early in the project approval process or during proposal writing efforts, allowing IMs to consider any unique data demands and initiate sound data management procedures. The IM team regularly contributes to research using JRN‚Äôs long-term core datasets, and therefore has a valuable perspective for overseeing these important projects. Recently, for example, the IM team led an effort to evaluate JRN‚Äôs long-term plant phenology data and revise the observation program to match National Phenology Network and NEON protocols (Elmendorf et al.¬†2016). Members of the IM team also manage their own research projects, advise JRN students and investigators, and contribute to journal articles.\nEducation and outreach: The JRN IM team prioritizes data-related leadership, education, and outreach by promoting the importance of Jornada data and sound data management practices, and building the data literacy and skills of Jornada investigators, students, and staff. Maurer and James are certified Carpentries instructors and have organized five scientific programming and data analysis workshops in the past 3 years. At the annual Jornada Desert Ecology Short Course, the IM team delivers a detailed Jornada Information Management presentation to students and researchers, and organizes ad-hoc events such as Data Jams (with Asombro), metadata clinics, or Carpentries workshops. Maurer holds weekly data-related office hours (Data Therapy Thursday) and James holds a monthly R work group.\nNetwork participation: Members of the JRN IM team actively contribute to the LTER Network‚Äôs IM activities in several capacities. From 2020-2023, Maurer served on the IM Executive committee for the network, including a term as co-chair, and he currently leads or participates in several EDI/LTER working groups. JRN contributes code, data, and expertise to several EDI and LTER data synthesis projects and collaborates closely with IMs from SEV, MCM, and NWT to organize education and outreach activities.\n\n\n\nMilestones in the current funding cycle: Since its last LTER renewal in 2018, JRN has developed a more efficient data publishing system, eased discovery and access of its diverse datasets, and enhanced data reusability by standardizing data and metadata. Milestones from the past four years include:\n\nA total of 386 JRN datasets are published at the EDI repository, with 291 newly created since the renewal, including many previously unpublished datasets from early JRN LTER projects. More than 330 datasets had data and/or metadata updated at least once in this period, with most long-term core datasets being updated yearly, and as frequently as monthly for over 30 weather station datasets (Fig. 2).\nWe created metabase and populated it with the rich metadata Jornada research programs have accumulated over the past 40 years. This system eased implementation of new data formatting and metadata content standards for almost all datasets in the JRN data catalog.\nNew standards and workflows to manage and publish specialized (non-tabular) datasets, such as ground-based and airborne imagery, were developed in collaboration with data managers in the LTER network and beyond (Gries et al.¬†2021).\nThe JRN data catalog was revised to enhance discovery and access to: (a) data published outside of EDI, (b) geospatial data, and (c), data from collaborating research networks and partners.\n\nFuture initiatives: The IM team will continue making steady improvements to the JRN IM system and the quality and FAIR status of JRN data. The next six years will bring significant changes to JRN research priorities and data, and the IM team plans to support these transitions. Planned improvements during JRN-8 are:\n\nThe IM team will expand its focus on the re-use of JRN data by harmonizing datasets, creating analysis-ready data products, and developing analytical applications. We will use open-source tools like R and Python, and leverage recent improvements in JRN metadata standards and publishing efficiency.\nJRN research projects continue to expand data collection via sensor networks. The IM team will extend the use of the MATLAB GCE Toolbox by implementing a new time series database for these data, and open-source tools to manage, publish, and access them efficiently. A pilot project for this began in 2023 in coordination with the HyMet working group, a joint effort of the LTER Network, EDI, CUAHSI, and the Dendra project. A side benefit of this work will be accessibility of real-time information about field conditions that will improve researcher safety.\nSeveral JRN-8 projects propose to collect and use ground-based and aerial imagery (e.g.¬†phenocams, UAS imagery) as a survey and monitoring method to complement or replace manual fieldwork. The IM team will respond with suitable data management protocols and accessibility tools.\nAs noted above, biological specimens and physical samples are a key product of JRN research. In JRN-8, the IM team will work to (a) identify JRN physical sample and specimen collections and make a comprehensive catalog accessible via the JRN website, and (b) develop new protocols to preserve and archive scientifically useful environmental samples (soil, biocrust, tissues), or resulting DNA extracts, into appropriate collections. For (b) we are discussing partnership options with the Museum of Southwestern Biology and the NEON Biorepository, and examining supplemental funding opportunities.\nThe Jornada Dryland Modeling team is proposing ecological modeling capabilities that will (a) consume observational datasets and other training data, (b) undergo intensive software development over time, and (c) produce simulation outputs for a variety of research questions and applications. The JRN IM team is embedded in this effort and will ensure that modeling activity and relevant data products are preserved and publicly accessible."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER8.html#introduction",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER8.html#introduction",
    "title": "Data Management Plan for JRN LTER-8",
    "section": "",
    "text": "The Jornada Basin LTER program (JRN) supports an effective and well-integrated information management (IM) program and shares the LTER Network view that published datasets are first-class products of research and an opportunity for outreach and education. The JRN Information Management (IM) system reliably performs a full range of essential data management functions to make research data and other information produced by the JRN program findable, accessible, interoperable, and re-usable (FAIR, Wilkinson et al.¬†2016). The team that designs and operates this system is guided by three core priorities.\n\nContribute to high quality, impactful ecology research at all stages of the data life cycle\nOversee, or directly handle, publication of all Jornada datasets\nAct as a source of data-related leadership, education, and outreach\n\nThe JRN IM team approaches each of these priorities with a philosophy of openness to diverse stakeholders, including scientists, resource managers, students, & the public, and a commitment to the principles of open scientific research. In this Data Management Plan, we review recent progress in JRN IM, and outline the strategy for managing and publishing JRN research data from 2025 to 2030."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER8.html#im-resources",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER8.html#im-resources",
    "title": "Data Management Plan for JRN LTER-8",
    "section": "",
    "text": "Personnel: The JRN IM team is headed by Dr.¬†Gregory Maurer, supported at 0.5 FTE by JRN. He leads a team comprised of a part-time computer programmer and part-time undergraduate assistants who contribute to data QA/QC, website content, and communications. The IM team works closely with JRN‚Äôs full-time site manager and program coordinator, and also collaborates closely with USDA data managers, including statistician Darren James, and local computing and network infrastructure managers Scott Schrader and Ken Ramsey. Maurer meets at least monthly with the JRN leadership team to align IM activities with research priorities, convey updates, and take feedback on data management standards and procedures.\nComputing and storage infrastructure: The JRN IM system is built on multiple technologies and infrastructure resources that provide secure, resilient computing and storage capabilities for JRN personnel, external collaborators, and the public. Most members of the JRN IM team have offices in Wooton Hall, headquarters of the USDA-ARS Jornada Experimental Range (JER), on New Mexico State University (NMSU) campus. A long-standing ARS-LTER agreement allows the JER to provide and manage some of the computing infrastructure that JRN requires (Table 1), including a server cluster with a 100TB storage block from which JRN staff are provided with networked file storage shares. Research data, IM-related metadata and tools, and staff files and documents (e.g., images, equipment manuals, procedures documents) are stored on these shares. Most other JRN IM infrastructure has transitioned to cloud-based systems in the last four years (Table 1) to reduce physical infrastructure maintenance demands and increase reliability and uptime. Linux virtual machines and S3-compatible object stores at DigitalOcean.com host databases with research metadata and other information (PostgreSQL 12), web-accessible storage for data entities, and full offsite backups of local Jornada file storage. The JRN website is built with WordPress and has several associated Javascript data catalog and bibliography applications, all of which are hosted at WPengine.com. Data catalogs and bibliography apps rely on API access to data stores at the Environmental Data Initiative (EDI) repository, Zotero.org, and NMSU‚Äôs ArcGIS Online instance. The JRN website‚Äôs interactive data viewer is hosted at the USDA-ARS-supported Shinyapps.io account. All cloud-based systems have a minimum of nightly backups with distributed storage and rollback ability. The JRN IM team backs up all shared local files nightly to an in-house device and the DigitalOcean S3 bucket, which is in addition to weekly, off-site tape-drive backups of the same data performed by USDA-ARS staff. Technology transfers update hardware, software, and file formats on a 3-5 year cycle to ensure long-term data protection against media or format obsolescence. Depending on project needs and institutional requirements, the IM team and researchers use a variety of secure cloud platforms (e.g.¬†Trello, GitHub, Dropbox or Google Drive) for online collaboration and storage of documentation, code, and other project information.\n\n\n\n\n\n\n\n\nImplemented service\nLocal/remote infrastructure\nSoftware\n\n\n\n\nNetworked file storage on NMSU campus\n100TB local storage block\nCIFS\n\n\nLTER-core-metabase metadata database\nDigitalOcean.com VM\nUbuntu Linux 20.04, PostgreSQL 12.16\n\n\nWeb-accessible data storage, offsite backups\nDigitalOcean.com Spaces\nS3-compatible object store\n\n\nJRN website and associated app hosting\nWPengine.com\nWordpress 6\n\n\nEDI data catalog app (JRN website)\nportal.edirepository.org\nPASTA+ API, Javascript\n\n\nBibliography, non-EDI data catalog apps (JRN website)\nZotero.org\nZotero API, Javascript\n\n\nInteractive data viewer (JRN website)\nShinyapps.io\nR Shiny (Javascript app builder)\n\n\nDocument storage/sharing for remote collaboration\nDropbox, Google Drive, GitHub\n\n\n\n\nTable 1: The information technology services used by JRN, along with the associated local or remote infrastructure and softwares responsible for implementing them.\nNetwork infrastructure: Servers and staff computers at Wooton Hall are connected to a Gigabit local area network (LAN) linked to the NMSU network (Gigabit Ethernet) through a firewall. Local networked systems and web applications are password-protected, and regular security sweeps identify security threats. The USDA Jornada field headquarters (HQ; centrally located at the LTER research site) is linked to the NMSU network via a 40 MB multi-hop, point-to-point wireless backhaul connection that can accommodate large-volume data. Field instruments are connected via spread spectrum wireless radios to base stations and the internet at HQ. Wireless internet at HQ is available for JRN LTER use."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER8.html#data-management-practices",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER8.html#data-management-practices",
    "title": "Data Management Plan for JRN LTER-8",
    "section": "",
    "text": "Jornada data management practices must accommodate diverse research activities and data products, ranging from tabular field data, to ground-based and airborne imagery, to ecological model outputs, to data from specimen and sample collections. The JRN IM system therefore uses several infrastructure components and procedures to create, manage, and distribute research data and other information in a modular way. Wherever possible the JRN IM team uses open-source tools and community standards. All documentation for the system is available in the group‚Äôs public GitHub organization (https://github.com/jornada-im), along with instructional materials for data-related education and outreach. Essential functions that the IM system delivers, with relevant components and processes, are described below. Stages of the DataONE data life cycle are identified in parentheses after section headings.\n\n\n\nFigure 1: A simplified schematic of the JRN Information Management system. Handling of a contributed JRN research dataset is depicted on the left, with infrastructure components (local and cloud-based) to the right. Labeled arrows depict data management processes, including a) the dataset submission, review, and revision process between IMs and researchers, b) data entry and backup to local and cloud infrastructure, c) dataset publication to EDI, d) cloud platform (EDI, shinyapps.io, ArcGIS Online, Zotero.org) API service calls updating the JRN website, and e) data and application updates to cloud platform services. Dashed arrows involve scripting and automation. Image credit xkcd.com.\n\n\n\n\n\nFigure 1: A simplified schematic of the JRN Information Management system. A research dataset contributed to the IM team is depicted on the left, with infrastructure components (local and cloud-based) to the right. Labeled arrows represent data management processes, including a) dataset submission, review, and revision in coordination with researchers, b) data entry and backup to local and cloud infrastructure, c) dataset publication to EDI, d) cloud platform (EDI, shinyapps.io, ArcGIS Online, Zotero.org) API service calls updating the JRN website, and e) data and application updates to cloud platform services. All dashed arrows involve some scripting and automation. Image credit xkcd.com.\n\n\n\nData collection and quality assurance (Collect, Assure): The IM team carefully tracks the status of Jornada research projects to ensure that collected data receive thorough quality checks before being published. Most data products from JRN projects are tabular in nature, and there are three primary entry points for this data into the JRN IM system: (1) collection of long-term datasets by the 3-person JRN field crew and site manager Anderson, (2) autonomous data collection by sensor networks and dataloggers, and (3) data submission by LTER investigators, students, and collaborators. For data entry point (1), field data collection schedules vary depending on the project, and site manager Anderson is responsible for archiving raw files and managing data entry/transcription and validation procedures. Anderson works closely with the rest of the IM team to quality assure and check (QA/QC) new data and produce files suitable for publication on an annual basis. To optimize efficiency, the IM team has developed custom workflows (in R, Python, Matlab, or Excel) to assist with QA/QC and generate output files. For entry point (2) we use the MATLAB GCE Toolbox (developed at GCE LTER) for data QA/QC, and have extended its functionality to allow rapid data flagging and publication to EDI using software developed by Ramirez and Anderson. For entry point (3), students and investigators QA/QC their own data and submit it with appropriate metadata to the IM team on a timeframe matching JRN and LTER data access policies (see below). Once data and metadata are submitted to the IM team, an additional layer of QA/QC and standardization is applied through database validation and custom R scripts (Fig. 1) during the data publication phase.\nThere are several classes of specialized JRN data products, including large datasets and non-tabular formats, that require a flexible approach to quality assurance. Biological specimens and physical samples destined for scientific collections are not assessed or otherwise handled directly by the IM team. Sequencing and genomic research generates datasets that are best assessed by those trained in bioinformatics. JRN modeling activities generate rapidly evolving code and parameter sets, and voluminous output/simulation data. Similarly, large collections of ground-based or airborne imagery are generated by multiple JRN research efforts. In each of these cases the JRN IM team has limited capacity to directly QA/QC the data. Instead, the focus is on training and coordination with the responsible researchers to ensure data quality and security, and collection of appropriate, descriptive metadata.\nData packaging and publishing (Describe, Preserve): To meet the FAIR data criteria, JRN strives to publish quality-assured data accompanied by rich, detailed metadata. Creating and publishing new datasets begins with submission of metadata using EDI‚Äôs ezEML tool, or a metadata template created by the IM team (MS Word or Excel formats). The IM team consults closely with researchers, students, and staff to determine what constitutes a useful dataset and how to describe one with metadata. Upon submission, the IM team stores and manages metadata for all tabular data products in a relational database following the LTER-core-metabase schema (metabase hereafter) which is maintained by a working group of the LTER Network Information Management Committee (IMC). This system validates and enforces standards, such as use of the LTER Controlled Vocabulary and Standard Units Dictionary, for incoming metadata. JRN also uses its own set of metadata standards and controlled vocabularies developed in consultation with Jornada researchers.\nThe JRN IM team publishes datasets in community-accepted online data repositories, with most going to the EDI data repository, which is closely affiliated with the LTER Network and focuses on metadata standards and data re-use. Before publication, the IM team error-checks and formats data files for usability, then uses an R-based workflow (MetaEgress and jerald packages) to extract metadata from metabase and generate an XML file formatted to the Ecological Metadata Language (EML) 2.2 standard. Data and EML files are then published together in EDI‚Äôs Provenance Aware Synthesis Tracking Architecture system (PASTA+). The consistency and integrity of all data and metadata is checked again by the PASTA+ system upon entering the repository. Datasets held at EDI constitute the primary JRN data catalog (Fig. 1), but some JRN data products are published elsewhere.\nSpecialized data products often have unique, community-standard data formats and metadata, and may benefit from alternative repository systems and publication methods. The IM team encourages and facilitates publication to non-EDI data repositories when logical to do so, and there are significant JRN data holdings in NCBI databases (sequencing and genomic data), AmeriFlux (flux towers), and the Phenocam network. Citation metadata for products in these repositories are entered into a Zotero library and listed in JRN‚Äôs non-EDI data catalog. In JRN-8 the IM team will begin placing new high-volume datasets (UAS imagery, acoustic monitoring data, model training data) into offline storage and making metadata records available in EDI. In all these cases the JRN IM team prioritizes providing high-quality metadata to allow others to discover the data, wherever it may reside, and assess its quality and fitness for use.\nFor specimens and samples collected during JRN research (a new data management focus), the IM team collaborates with investigators to identify suitable partner museums or natural history collections, assemble appropriate metadata, and then accession the physical items into the collection, and metadata into an accessible database (e.g.¬†Arctos, Symbiota). Plant and vertebrate voucher specimens are currently sent to the NMSU Herbaria and NMSU Wildlife Museums, respectively, and less-frequently collected specimens, like invertebrates, have been accessioned into a range of other collections in the past. Decades of Jornada soil survey and pedology samples have been archived at the NRCS National Soil Archive. When accessioning specimens and samples into established collections is not possible, the JRN IM team ensures stable local storage, catalogs all appropriate metadata, and makes the collection accessible on the JRN website. Some physical samples, including aeolian dust, atmospheric deposition, and plant tissue samples, are already handled this way. In recent years at JRN, environmental samples like soils, biocrusts, tissues, fecal pellets, and DNA extracts are being collected for metabarcoding, metagenomics, and other sequencing-based methods of investigation. Most of these are currently archived in investigator or departmental laboratory facilities (-80 freezers). In JRN-8, the IM team is proposing new protocols to handle these samples and associated data; see item 4 under ‚ÄúFuture initiatives‚Äù below.\n\n\n\nFigure 2: A plot of JRN‚Äôs PASTA+ database activity (knb-lter-jrn scope) at the EDI repository since the 2020 JRN-8 proposal submission. Panel A: Cumulative dataset creation and update events. Panel B: Daily data downloads for JRN datasets. Known robots have been removed.\n\n\n\n\n\nFigure 2: A plot of JRN‚Äôs PASTA+ database activity (knb-lter-jrn scope) at the EDI repository since the 2020 JRN-8 proposal submission. Panel A: Cumulative dataset creation and update events. Panel B: Daily data downloads for JRN datasets. Known robots have been removed. \n\n\n\nData archiving and access policies (Preserve, Discover): In adherence with the Type I data guidelines described in the LTER Network Data Access Policy, JRN strives to publish all research data no more than 2 years after collection or at the time of journal article publication. Long-term core research datasets are prioritized highest for publication within this 2 year period, while student thesis data receive lower publication priority as students finish, and datasets from early, previously unpublished JRN studies are published as time allows. To ensure compliance with this policy, JRN strongly encourages timely submission and archiving of research data from all supported projects. Investigators and students, particularly those receiving JRN graduate fellowships or other funds, are required to submit data to the IM team within a year of research project initiation, and annually thereafter for long-term research. The IM team regularly communicates these requirements directly to PIs and students at JRN meetings and training events. At present, no Type II data are collected at JRN.\nData published in the primary JRN data catalog are publicly accessible in three locations: the JRN website, EDI, and the DataONE metadata aggregator through EDI‚Äôs membership. Almost all JRN datasets are published with the Creative Commons ‚ÄúCCBY‚Äù or ‚ÄúCC0‚Äù license, with minor exceptions for JRN data published in non-EDI repositories (e.g.¬†NCBI). Detailed spatial data for research sites and instrumentation in areas accessible to the public (JER and the Chihuahuan Desert Rangeland Research Center) are withheld from public metadata but are available to researchers upon request.\nThe JRN website (Plan, Discover): The JRN website (https://lter.jornada.nmsu.edu) is the central means of exposing all aspects of research, education, and outreach activities in an accessible and user-friendly way. It conveys this information through a mix of static and interactive pages featuring site and program descriptions, blog posts, maps, research vignettes, and other materials. Website information is updated regularly and designed for effective communication with JRN scientists, staff, external collaborators, and the public.\nThe JRN website has two main data-related functions. First, it directly communicates important information about collecting and sharing data to JRN researchers and staff. The ‚ÄúFor Researchers‚Äù menu covers important topics such as (a) procedures for initiating new research, (b) site and field safety information, (c) conduct and inclusive research expectations, (d) incident reporting, and (e) expectations and procedures for contributing Jornada data, specimens, and samples. The IM team ensures that this content is accessible, clear, and actionable. Second, the website is the gateway for discovery and access to JRN data. The website data catalog is multi-faceted and includes capable browsing and search tools. The primary website data catalog queries the EDI repository using the PASTA+ API and returns results that link directly to dataset landing pages on EDI, meaning that the data catalog always reflects current JRN holdings on EDI. Other facets of the data catalog allow discovery of non-EDI datasets, spatial data, biological specimens and physical samples, and data available from JRN‚Äôs non-LTER research partners.\nAccess to JRN publication and personnel listings is provided via website applications as well. For publications, an LTER-community maintained javascript application provides access to a Zotero.org-backed JRN bibliography of peer-reviewed journal articles, book chapters, reports, and theses. Current JRN personnel are featured on the website using a WordPress plugin, which the IM team populates from an extensive personnel database that reaches back to the beginning of the program."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER8.html#additional-im-activities",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER8.html#additional-im-activities",
    "title": "Data Management Plan for JRN LTER-8",
    "section": "",
    "text": "IM integration with research (Plan, Describe, Integrate, Analyze): The IM team is composed of experienced ecologists, statisticians, and computer scientists (and students in these fields) who contribute to JRN research in a range of scientific capacities. They work closely with Jornada investigators to ensure that research projects are soundly designed, address high-priority JRN research objectives, and meet all open science and data management standards and obligations. For new research, IM involvement typically begins early in the project approval process or during proposal writing efforts, allowing IMs to consider any unique data demands and initiate sound data management procedures. The IM team regularly contributes to research using JRN‚Äôs long-term core datasets, and therefore has a valuable perspective for overseeing these important projects. Recently, for example, the IM team led an effort to evaluate JRN‚Äôs long-term plant phenology data and revise the observation program to match National Phenology Network and NEON protocols (Elmendorf et al.¬†2016). Members of the IM team also manage their own research projects, advise JRN students and investigators, and contribute to journal articles.\nEducation and outreach: The JRN IM team prioritizes data-related leadership, education, and outreach by promoting the importance of Jornada data and sound data management practices, and building the data literacy and skills of Jornada investigators, students, and staff. Maurer and James are certified Carpentries instructors and have organized five scientific programming and data analysis workshops in the past 3 years. At the annual Jornada Desert Ecology Short Course, the IM team delivers a detailed Jornada Information Management presentation to students and researchers, and organizes ad-hoc events such as Data Jams (with Asombro), metadata clinics, or Carpentries workshops. Maurer holds weekly data-related office hours (Data Therapy Thursday) and James holds a monthly R work group.\nNetwork participation: Members of the JRN IM team actively contribute to the LTER Network‚Äôs IM activities in several capacities. From 2020-2023, Maurer served on the IM Executive committee for the network, including a term as co-chair, and he currently leads or participates in several EDI/LTER working groups. JRN contributes code, data, and expertise to several EDI and LTER data synthesis projects and collaborates closely with IMs from SEV, MCM, and NWT to organize education and outreach activities."
  },
  {
    "objectID": "proposals-and-reports/JRN_data_management_plan.LTER8.html#recent-accomplishments-and-future-initiatives",
    "href": "proposals-and-reports/JRN_data_management_plan.LTER8.html#recent-accomplishments-and-future-initiatives",
    "title": "Data Management Plan for JRN LTER-8",
    "section": "",
    "text": "Milestones in the current funding cycle: Since its last LTER renewal in 2018, JRN has developed a more efficient data publishing system, eased discovery and access of its diverse datasets, and enhanced data reusability by standardizing data and metadata. Milestones from the past four years include:\n\nA total of 386 JRN datasets are published at the EDI repository, with 291 newly created since the renewal, including many previously unpublished datasets from early JRN LTER projects. More than 330 datasets had data and/or metadata updated at least once in this period, with most long-term core datasets being updated yearly, and as frequently as monthly for over 30 weather station datasets (Fig. 2).\nWe created metabase and populated it with the rich metadata Jornada research programs have accumulated over the past 40 years. This system eased implementation of new data formatting and metadata content standards for almost all datasets in the JRN data catalog.\nNew standards and workflows to manage and publish specialized (non-tabular) datasets, such as ground-based and airborne imagery, were developed in collaboration with data managers in the LTER network and beyond (Gries et al.¬†2021).\nThe JRN data catalog was revised to enhance discovery and access to: (a) data published outside of EDI, (b) geospatial data, and (c), data from collaborating research networks and partners.\n\nFuture initiatives: The IM team will continue making steady improvements to the JRN IM system and the quality and FAIR status of JRN data. The next six years will bring significant changes to JRN research priorities and data, and the IM team plans to support these transitions. Planned improvements during JRN-8 are:\n\nThe IM team will expand its focus on the re-use of JRN data by harmonizing datasets, creating analysis-ready data products, and developing analytical applications. We will use open-source tools like R and Python, and leverage recent improvements in JRN metadata standards and publishing efficiency.\nJRN research projects continue to expand data collection via sensor networks. The IM team will extend the use of the MATLAB GCE Toolbox by implementing a new time series database for these data, and open-source tools to manage, publish, and access them efficiently. A pilot project for this began in 2023 in coordination with the HyMet working group, a joint effort of the LTER Network, EDI, CUAHSI, and the Dendra project. A side benefit of this work will be accessibility of real-time information about field conditions that will improve researcher safety.\nSeveral JRN-8 projects propose to collect and use ground-based and aerial imagery (e.g.¬†phenocams, UAS imagery) as a survey and monitoring method to complement or replace manual fieldwork. The IM team will respond with suitable data management protocols and accessibility tools.\nAs noted above, biological specimens and physical samples are a key product of JRN research. In JRN-8, the IM team will work to (a) identify JRN physical sample and specimen collections and make a comprehensive catalog accessible via the JRN website, and (b) develop new protocols to preserve and archive scientifically useful environmental samples (soil, biocrust, tissues), or resulting DNA extracts, into appropriate collections. For (b) we are discussing partnership options with the Museum of Southwestern Biology and the NEON Biorepository, and examining supplemental funding opportunities.\nThe Jornada Dryland Modeling team is proposing ecological modeling capabilities that will (a) consume observational datasets and other training data, (b) undergo intensive software development over time, and (c) produce simulation outputs for a variety of research questions and applications. The JRN IM team is embedded in this effort and will ensure that modeling activity and relevant data products are preserved and publicly accessible."
  },
  {
    "objectID": "proposals-and-reports/index.html",
    "href": "proposals-and-reports/index.html",
    "title": "Recent proposals and reports",
    "section": "",
    "text": "Recent proposals and reports\n\nThe JRN-8 Data Management Plan for the 2024 LTER renewal proposal.\nThe JRN-VII Data Management Plan for the 2020 LTER renewal proposal (after probation).\nThe 2020 JRN IM Annual Report"
  },
  {
    "objectID": "proposals-and-reports/JRN_IM_annual_report_2020.html",
    "href": "proposals-and-reports/JRN_IM_annual_report_2020.html",
    "title": "Jornada Basin LTER Information Management 2020 Annual Report (DRAFT)",
    "section": "",
    "text": "This document summarizes the accomplishments of the Jornada Basin LTER (JRN) Information Management (IM) team in 2020, and outlines activity planned for 2021. Most of the work described here has been, or will be, guided by what the IM team wrote in the Data Management Plan submitted with our 2020 LTER proposal. In the late summer of 2020 we received word that the LTER proposal was recommended for funding beginning in early 2021. The Data Managment Plan received generally favorable feedback from the NSF review panel."
  },
  {
    "objectID": "proposals-and-reports/JRN_IM_annual_report_2020.html#jrn-websites",
    "href": "proposals-and-reports/JRN_IM_annual_report_2020.html#jrn-websites",
    "title": "Jornada Basin LTER Information Management 2020 Annual Report (DRAFT)",
    "section": "JRN Websites",
    "text": "JRN Websites\n\nA new JRN website was built and began service in June 2020.\nA new partner data catalog was added to the website.\nA new interactive data viewer was made available on the website (Geovany), and further additions to this were discussed.\nAn improved spatial data catalog was added to the new website, and further improvements were planned.\nA number of updates to the Jornada IM websitewere completed, including new documentation, improved metadata templates, IM diagnostics, and data access/analysis tools."
  },
  {
    "objectID": "proposals-and-reports/JRN_IM_annual_report_2020.html#metadata-database",
    "href": "proposals-and-reports/JRN_IM_annual_report_2020.html#metadata-database",
    "title": "Jornada Basin LTER Information Management 2020 Annual Report (DRAFT)",
    "section": "Metadata database",
    "text": "Metadata database\n\nJRN-metabase, a PostgreSQL database following the LTER-core-metabase schema, was created and made available for testing on the DASH server.\nGreg and Shelly (and formerly Haneen Omari) populated this database with metadata for all JRN ‚Äúcore‚Äù packages, and all recently updated ‚Äúnon-core‚Äù data packages.\nWe successfully made valid EML (XML metadata documents) using the database as a backend.\nWe expect JRN-metabase (and associated R code) to enter service for building metadata documents (EML) for the Jornada‚Äôs EDI data packages by March 2021.\nAlternative server locations for hosting this database are currently under consideration."
  },
  {
    "objectID": "proposals-and-reports/JRN_IM_annual_report_2020.html#harmonizing-jornada-data",
    "href": "proposals-and-reports/JRN_IM_annual_report_2020.html#harmonizing-jornada-data",
    "title": "Jornada Basin LTER Information Management 2020 Annual Report (DRAFT)",
    "section": "Harmonizing Jornada data",
    "text": "Harmonizing Jornada data\n\nGreg began a project to assemble and harmonize Jornada NPP and related data.\nDarren James and the Peters research group began working on new projects harmonizing Jornada precipitation data.\nThe IM team identified several potential harmonized datasets to add to the interactive data viewer beginning in 2021."
  },
  {
    "objectID": "proposals-and-reports/JRN_IM_annual_report_2020.html#project-level-metadata-and-spatial-data-issues",
    "href": "proposals-and-reports/JRN_IM_annual_report_2020.html#project-level-metadata-and-spatial-data-issues",
    "title": "Jornada Basin LTER Information Management 2020 Annual Report (DRAFT)",
    "section": "Project-level metadata and spatial data issues",
    "text": "Project-level metadata and spatial data issues\nThere are some workflows for creating, organizing, and tracking projects and their location data at the Jornada. For instance, John Anderson‚Äôs ‚ÄúResearch notification‚Äù system tracks approved research projects and should, in theory, initiate collection of metadata for each project. However, research projects commonly suffer from a lack of metadata collection and accessibility after the approval phase, and information gathered during the approval phase is not widely accessible to Jornada researchers or the public. Some things that would help address this problem:\n\nA project metadata database (what experiments are happening or have happened, who is in charge, what are the questions, measurements, infrastructure) that is accessible to John and other project managers.\nA ‚Äúcanonical‚Äù spatial database for the Jornada that links to project IDs. This spatial database would house plot locations, sensor locations, and other coordinates telling users where experiments happened over time.\nA reference collection of ancillary spatial data products (roads, fence lines, vegetation, geomorphology). We have some of this, but its not very complete and there are multiple copies of everything.\n\nEach of these resources would be most useful when shared among multiple partners at the Jornada (LTAR, LTER, etc.). The Jornada IT infrastructure and data management working group, which includes USDA, Landscape Data Commons, and LTER staff, is beginning to address some of these issues and tasks in a coordinated way."
  },
  {
    "objectID": "proposals-and-reports/JRN_IM_annual_report_2020.html#outreach-initiatives",
    "href": "proposals-and-reports/JRN_IM_annual_report_2020.html#outreach-initiatives",
    "title": "Jornada Basin LTER Information Management 2020 Annual Report (DRAFT)",
    "section": "Outreach initiatives",
    "text": "Outreach initiatives\n\nThere is no shared communication platform for messaging among Jornada investigators, students, and staff. This tends to fragment Jornada communication and makes cohesive messaging for JRN community activities a challenge. Some of our future initiatives, such as Data Bounty Hunters, would greatly benefit from such a platform. A Mailman server, mailing list/group web services (MailChimp, Groups.io), or messaging platforms (Zulip, Slack) are possible candidates, but we need either infrastructure or budget to adopt these.\nIt may be difficult to spend LTER budget for non-research activity, but we need some funds to make Jornada T-Shirts, hats, or stickers that could be used to encourage/reward participation in Jornada outreach initiatives (Data Bounty Hunters, for instance again)."
  },
  {
    "objectID": "proposals-and-reports/JRN_IM_annual_report_2020.html#infrastructure",
    "href": "proposals-and-reports/JRN_IM_annual_report_2020.html#infrastructure",
    "title": "Jornada Basin LTER Information Management 2020 Annual Report (DRAFT)",
    "section": "Infrastructure",
    "text": "Infrastructure\nAs described in above, the JRN IM Team needs server resources to host databases, web services, a communication platform, and potentially a future version of our website. Because JRN is partnered with the USDA Jornada Experimental Range (JER) and JER has existing server resources and sysadmins, appropriating some of these JER resources for JRN use (and contributing back to supporting the system) would be the most efficient & cost-effective solution for JRN to meet its IT needs. Currently, however, this option does not appear viable because the JER server infrastructure is out of date and undergoing a long transition to a more modern, stable, and supportable system. Thus, in 2020 the IM team was unable to provision a virtual server on this system. While we await progress on JER server systems, we are investigating ways we can meet our IT needs using NMSU or cloud providers (AWS, Google services), but these will require some LTER budget. Any suggestions regarding server resources available at Jornada or partner institutions are welcomed by the IM team.\nAgain, the Jornada IT infrastructure and data management working group, is beginning to address some of these issues in a coordinated way."
  },
  {
    "objectID": "docs/researcher/overview.html",
    "href": "docs/researcher/overview.html",
    "title": "Research approval and policies",
    "section": "",
    "text": "This page was written by Jornada information managers (IMs) to provide a concise, but fairly comprehensive guide to research administration and data management for Jornada students and investigators, including PIs, postdocs, graduate students, undergraduate researchers, and staff scientists.",
    "crumbs": [
      "Researcher Guide",
      "Overview"
    ]
  },
  {
    "objectID": "docs/researcher/overview.html#ezeml",
    "href": "docs/researcher/overview.html#ezeml",
    "title": "Research approval and policies",
    "section": "ezEML",
    "text": "ezEML\nThe EDI repository has created a web app called ezEML for describing research datasets and creating standardized metadata documents for publication (EML). The tool is new but has rapidly developed to become an excellent method to author well-documented datasets. There is a Jornada EML template available on the site, so the recommended process for Jornada researchers is:\n\nLog in to ezEML using your Google, GitHub, or ORCID account (whichever is easiest).\nStart a new EML document using the ‚ÄúEML Documents &gt; New from Template‚Äù menu item\nNavigate to and select the ‚ÄúLTER/JRN/JRN_template_general‚Äù template to open a document template pre-populated with Jornada metadata.\nGive the document a unique name. You can save your metadata and then return to this document anytime.\nFollow the sequence of forms on the left, and ezEML‚Äôs prompts, to upload data files and enter metadata for your dataset. Each section of your metadata will have help available (‚Äú?‚Äù icons) and several fields will already be filled if you are using the JRN template.\nUse the ‚ÄúCheck metadata‚Äù and ‚ÄúCheck data tables‚Äù tools at the bottom left to check the completeness and validity of your dataset. Green lights mean your dataset is well described and ready to share.\nWhen ready, click ‚ÄúSubmit/Share Package‚Äù and then ‚ÄúCollaborate with Colleagues‚Äù. DO NOT USE ‚ÄúSubmit Package to EDI‚Äù or we may miss your dataset.\nOn the ‚ÄúInvite a Collaborator‚Äù screen share the dataset with a Jornada data manager (mailto:jornada.data@nmsu.edu).\n\nAt this point, the Jornada IM Team will receive a notification and can access your dataset in ezEML to review, edit, and publish to EDI.",
    "crumbs": [
      "Researcher Guide",
      "Overview"
    ]
  },
  {
    "objectID": "docs/researcher/overview.html#metadata-templates",
    "href": "docs/researcher/overview.html#metadata-templates",
    "title": "Research approval and policies",
    "section": "Metadata templates",
    "text": "Metadata templates\nA metadata template is a document with a structure and cues that help you collect the essential metadata needed to describe a published dataset. We have created Jornada metadata templates in MS Word (.docx) or Excel (.xlsx) formats. These templates contain sections for all critical pieces of metadata, along with instructions on what to include and how to structure the information. The Excel version is slightly more detailed and may be useful for complex datasets. Completed templates and accompanying data files should be sent to the Jornada IM team (mailto:jornada.data@nmsu.edu).",
    "crumbs": [
      "Researcher Guide",
      "Overview"
    ]
  },
  {
    "objectID": "docs/researcher/overview.html#general-jornada-metadata-guidelines",
    "href": "docs/researcher/overview.html#general-jornada-metadata-guidelines",
    "title": "Research approval and policies",
    "section": "General Jornada metadata guidelines",
    "text": "General Jornada metadata guidelines\nWhile writing metadata, the Jornada metadata standards (.docx) and keyword thesauri (.xlsx) documents are helpful, but not required.",
    "crumbs": [
      "Researcher Guide",
      "Overview"
    ]
  },
  {
    "objectID": "docs/im/hacks/parse_trello_boards.html",
    "href": "docs/im/hacks/parse_trello_boards.html",
    "title": "Parsing trello boards to csv",
    "section": "",
    "text": "Parsing trello boards to csv\n\nFrom Trello board go to\nMenu &gt; More &gt; Print and Export &gt; Export as JSON\nand download the JSON to a local machine.\nParse the raw JSON to a simplified tabular JSON file that can be converted to csv.\n\nDownload the Trello JSON parser code and make executable some where on local machine.\nRun trelloparse {trello JSON file.json} output.json\n\nConvert output.json to .csv using https://json-csv.com",
    "crumbs": [
      "IM Guide",
      "Hacks",
      "Parsing trello boards to csv"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html",
    "href": "docs/im/sysadmin/chapter-04-databases.html",
    "title": "4. Databases",
    "section": "",
    "text": "JRN Metabase (jrn_metabase) is a PostgreSQL database that can be stored and accessed on either a local or remote host. Generally we configure it on a remote host for multi-user access. PostgreSQL uses a client/server model, which means that the database server application (postgres) runs on the host system and manages the databases and all incoming connections from client applications. Users can choose from a number of client applications to connect to a server and database(s), either locally (from the server‚Äôs host machine), or remotely. The standard, commandline client interface to PostgreSQL is psql, which can be, or already is, installed on most computers. We also use DBeaver as a graphical client for jrn_metabase. Links to PostgreSQL and community documentation are on the Postgres Links page.\n\n\nFor the remote host, we use an Ubuntu server running an up-to-date PostgreSQL server. To access a remote host over a terminal connection use:\nssh &lt;username&gt;@&lt;host name or IP&gt;\nNote that if the host you are accessing is a Jornada server you will need to use the Jornada VPN from outside Wooton Hall.\nTo install PostgreSQL, use the most current installation method for the host‚Äôs operating system. We installed the default packages available in the latest version of Ubuntu Server. In Linux systems (Ubuntu, Debian, macOS, etc), installation of PostgreSQL creates a system user and a database server role that are both named postgres. The PostgreSQL administrative shell client, called `psql‚Äô, is also installed by default. Many more details on PostgreSQL server administration setup and administration can be found in the official PG Administrator Guide.\n\n\nWhen logged into the PostgreSQL host, any system user with sudoer privileges can switch to the postgres user and enter the psql shell with:\nsudo -u postgres psql\nThe postgres=# prompt will appear indicating you have entered the shell in the postgres role, which is the default administrative role with superuser privileges. It has no password set on a new install(, so that will need to be set according to instructions below.)\nOther PostgreSQL roles should be created for database users. Once these are created and remote access is configured on the host, psql can be run from remote clients (if installed) so that users can login to databases on the host using commands like:\npsql -U &lt;rolename&gt; -h &lt;hostname or IP&gt; -p &lt;postgres port&gt; &lt;database name&gt;\nIn general the postgres port is 5432.\n\n\n\nThere are several configurations to set to allow remote access to a PostgreSQL database cluster. Some of these changes involve editing config files and some involve using psql. Most likely you‚Äôll do this from your user account on the host machine. Check these instructions for updates.\n\nEdit postgresql.conf to allow remote connections. To do this, open the file (usually in /etc/postgresql/&lt;version&gt;/main) and locate the listen_addresses='localhost' line, uncomment if needed, and change it to:\nlisten_addresses=‚Äò*‚Äô\nNow give the postgres user a password. Enter the psql as the default user (postgres)\n sudo -u postgres psql  # assuming logged on to host as a sudoer\nThen change the postgres role‚Äôs password to something more secure\n postgres=# ALTER USER postgres WITH ENCRYPTED PASSWORD '&lt;password&gt;';\nAlter the PostgreSQL authentication config file to allow user postgres to authenticate with md5 when making a remote (TCP/IP) connection.\n sudo vim /etc/postgresql/12/main/pg_hba.conf\nAdd a line that looks like like this:\n hostssl   template1         postgres     0.0.0.0/0       scram-sha-256\nYou could also restrict by database, or ip.\nFor other users, you can add a similar line to pg_hba.conf beneath the one above to allow remote connections - just change postgres to the user name. This can allow users from any IP (0.0.0.0/0) to login using md5. You could also let all users in this way:\nhost    all     all      0.0.0.0/0      md5\nBut it isn‚Äôt that secure.\n\n\n\n\nThere are some recommended roles to add to a PostgreSQL cluster for LTER_core_metabase (defined here). This will most likely be done in psql while logged into the host.\n\nCreate a role for the database owner and set password\n postgres=# CREATE ROLE &lt;name&gt; CREATEDB CREATEROLE LOGIN;\n postgres=# ALTER USER &lt;name&gt; WITH ENCRYPTED PASSWORD '&lt;password&gt;';\nCreate other roles specified for LTER_core_metabase. If you create these before creating the LTER_core_metabase in the steps below, they will be granted the correct permissions to the schema and tables.\n CREATE ROLE read_write_metabase;\n CREATE ROLE read_only_metabase;\nIf for some reason permissions for these roles need correction, or a new role needs to be added, you might need to re-run the permission granting section in the database dump for LTER-core-metabase (onebigfile.sql), potentially after substituting in the new role name. JRN created a separate user for one of its metabases (jrn_metabase_dev) using this method.\nAfter making changes on server restart the postgres server.\n sudo systemctl restart postgresql.service\n\n\n\n\n\n\n\nThere are some PostgreSQL tools available in Linux userspace, so while logged in to the host, you can create a testing database for a user role with:\ncreatedb -O &lt;username&gt; &lt;databasename&gt;\nOr you can log into psql as a particular role and do:\nusername=# CREATE DATABASE &lt;databasename&gt;\nOnce this database is created you can log in to the database from the system shel (Note the uppercase -U flag to denote the user):\npsql -U &lt;username&gt; &lt;databasename&gt;\nOr connect from within psql:\nusername=# \\c &lt;databasename&gt;\nAfter logging in you can issue SQL commands and queries or use the psql metacommands that are prepended by a backslash and described here.\n\n\n\nAt Jornada, we are basically using a ‚Äústock‚Äù version of LTER-core-metabase. It only takes a few minor modifications to install the source.\n\nOn the host machine, clone the lter_core_metabase git repository then cd into the directory.\nEdit the 2 sql files, sql/00_create_db.sql and sql/onebigfile.sql, to replace ‚Äò%db_owner%‚Äô with the name of the database owner role you created. This could be done with a standard text editor or sed.\nCreate the database:\n sudo -u postgres psql -f GitHub/LTER-core-metabase/sql/00_create_db.sql\nIf there is a locale error you may edit locales in 00_create_db.sql to one present on your system (C.UTF-8 worked best for JRN), and/or create a new locale for your system (locale-gen...).\nSet up the schema with onebigfile.sql (this is if logged on to host).\n psql -U &lt;db_owner username&gt; -h localhost -d lter_core_metabase &lt; GitHub/LTER-core-metabase/sql/onebigfile.sql\n\n\n\n\nThere are patches created for LTER_core_metabase periodically that may add new features or fix bugs between versions. These are in the migration branch of the LTER-core-metabase GitHub repository. You should only apply the patches that are not already in onebigfile.sql and have not been already installed to your metabase. Check which patches are installed by consulting the pkg_mgmt.version_tracker_metabase table.\nSome logical steps to install a patch are:\n\nLog on to the server running jrn_metabase\nPull any changes from LTER-core-metabase repository.\nMake a copy of the patches for local editing:\ncp sql/44_add_provider_id_taxonomy_vw.sql sql_jrn/44_add_provider_id_taxonomy_vw.jrn.sql\nEdit the patch to make it compatibile with your metabase configuration. In most cases (assuming the patch is well-tessted) this should easy, and the main task is usually to replace %db_owner% with the appropriate Postgres role for the installed metabase.\nvim sql_jrn/33_semantic_annotation.jrn.sql\nRun the patch SQL by logging to the target database as postgres (or another authorized user; sudo -u postgres psql jrn_metabase) and issuing:\n\\i GitHub/LTER-core-metabase/sql_jrn/33_semantic_annotation.jrn.sql\nusing psql from the system prompt may work, though there may be permission problems with this:\npsql -U &lt;username&gt; -h &lt;hostname&gt; -d &lt;databasename&gt; &lt; GitHub/LTER-core-metabase/sql_jrn/33_semantic_annotation.sql\nCheck that the patch was applied correctly!",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#host-setup",
    "href": "docs/im/sysadmin/chapter-04-databases.html#host-setup",
    "title": "4. Databases",
    "section": "",
    "text": "For the remote host, we use an Ubuntu server running an up-to-date PostgreSQL server. To access a remote host over a terminal connection use:\nssh &lt;username&gt;@&lt;host name or IP&gt;\nNote that if the host you are accessing is a Jornada server you will need to use the Jornada VPN from outside Wooton Hall.\nTo install PostgreSQL, use the most current installation method for the host‚Äôs operating system. We installed the default packages available in the latest version of Ubuntu Server. In Linux systems (Ubuntu, Debian, macOS, etc), installation of PostgreSQL creates a system user and a database server role that are both named postgres. The PostgreSQL administrative shell client, called `psql‚Äô, is also installed by default. Many more details on PostgreSQL server administration setup and administration can be found in the official PG Administrator Guide.\n\n\nWhen logged into the PostgreSQL host, any system user with sudoer privileges can switch to the postgres user and enter the psql shell with:\nsudo -u postgres psql\nThe postgres=# prompt will appear indicating you have entered the shell in the postgres role, which is the default administrative role with superuser privileges. It has no password set on a new install(, so that will need to be set according to instructions below.)\nOther PostgreSQL roles should be created for database users. Once these are created and remote access is configured on the host, psql can be run from remote clients (if installed) so that users can login to databases on the host using commands like:\npsql -U &lt;rolename&gt; -h &lt;hostname or IP&gt; -p &lt;postgres port&gt; &lt;database name&gt;\nIn general the postgres port is 5432.\n\n\n\nThere are several configurations to set to allow remote access to a PostgreSQL database cluster. Some of these changes involve editing config files and some involve using psql. Most likely you‚Äôll do this from your user account on the host machine. Check these instructions for updates.\n\nEdit postgresql.conf to allow remote connections. To do this, open the file (usually in /etc/postgresql/&lt;version&gt;/main) and locate the listen_addresses='localhost' line, uncomment if needed, and change it to:\nlisten_addresses=‚Äò*‚Äô\nNow give the postgres user a password. Enter the psql as the default user (postgres)\n sudo -u postgres psql  # assuming logged on to host as a sudoer\nThen change the postgres role‚Äôs password to something more secure\n postgres=# ALTER USER postgres WITH ENCRYPTED PASSWORD '&lt;password&gt;';\nAlter the PostgreSQL authentication config file to allow user postgres to authenticate with md5 when making a remote (TCP/IP) connection.\n sudo vim /etc/postgresql/12/main/pg_hba.conf\nAdd a line that looks like like this:\n hostssl   template1         postgres     0.0.0.0/0       scram-sha-256\nYou could also restrict by database, or ip.\nFor other users, you can add a similar line to pg_hba.conf beneath the one above to allow remote connections - just change postgres to the user name. This can allow users from any IP (0.0.0.0/0) to login using md5. You could also let all users in this way:\nhost    all     all      0.0.0.0/0      md5\nBut it isn‚Äôt that secure.\n\n\n\n\nThere are some recommended roles to add to a PostgreSQL cluster for LTER_core_metabase (defined here). This will most likely be done in psql while logged into the host.\n\nCreate a role for the database owner and set password\n postgres=# CREATE ROLE &lt;name&gt; CREATEDB CREATEROLE LOGIN;\n postgres=# ALTER USER &lt;name&gt; WITH ENCRYPTED PASSWORD '&lt;password&gt;';\nCreate other roles specified for LTER_core_metabase. If you create these before creating the LTER_core_metabase in the steps below, they will be granted the correct permissions to the schema and tables.\n CREATE ROLE read_write_metabase;\n CREATE ROLE read_only_metabase;\nIf for some reason permissions for these roles need correction, or a new role needs to be added, you might need to re-run the permission granting section in the database dump for LTER-core-metabase (onebigfile.sql), potentially after substituting in the new role name. JRN created a separate user for one of its metabases (jrn_metabase_dev) using this method.\nAfter making changes on server restart the postgres server.\n sudo systemctl restart postgresql.service",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#creating-databases",
    "href": "docs/im/sysadmin/chapter-04-databases.html#creating-databases",
    "title": "4. Databases",
    "section": "",
    "text": "There are some PostgreSQL tools available in Linux userspace, so while logged in to the host, you can create a testing database for a user role with:\ncreatedb -O &lt;username&gt; &lt;databasename&gt;\nOr you can log into psql as a particular role and do:\nusername=# CREATE DATABASE &lt;databasename&gt;\nOnce this database is created you can log in to the database from the system shel (Note the uppercase -U flag to denote the user):\npsql -U &lt;username&gt; &lt;databasename&gt;\nOr connect from within psql:\nusername=# \\c &lt;databasename&gt;\nAfter logging in you can issue SQL commands and queries or use the psql metacommands that are prepended by a backslash and described here.\n\n\n\nAt Jornada, we are basically using a ‚Äústock‚Äù version of LTER-core-metabase. It only takes a few minor modifications to install the source.\n\nOn the host machine, clone the lter_core_metabase git repository then cd into the directory.\nEdit the 2 sql files, sql/00_create_db.sql and sql/onebigfile.sql, to replace ‚Äò%db_owner%‚Äô with the name of the database owner role you created. This could be done with a standard text editor or sed.\nCreate the database:\n sudo -u postgres psql -f GitHub/LTER-core-metabase/sql/00_create_db.sql\nIf there is a locale error you may edit locales in 00_create_db.sql to one present on your system (C.UTF-8 worked best for JRN), and/or create a new locale for your system (locale-gen...).\nSet up the schema with onebigfile.sql (this is if logged on to host).\n psql -U &lt;db_owner username&gt; -h localhost -d lter_core_metabase &lt; GitHub/LTER-core-metabase/sql/onebigfile.sql\n\n\n\n\nThere are patches created for LTER_core_metabase periodically that may add new features or fix bugs between versions. These are in the migration branch of the LTER-core-metabase GitHub repository. You should only apply the patches that are not already in onebigfile.sql and have not been already installed to your metabase. Check which patches are installed by consulting the pkg_mgmt.version_tracker_metabase table.\nSome logical steps to install a patch are:\n\nLog on to the server running jrn_metabase\nPull any changes from LTER-core-metabase repository.\nMake a copy of the patches for local editing:\ncp sql/44_add_provider_id_taxonomy_vw.sql sql_jrn/44_add_provider_id_taxonomy_vw.jrn.sql\nEdit the patch to make it compatibile with your metabase configuration. In most cases (assuming the patch is well-tessted) this should easy, and the main task is usually to replace %db_owner% with the appropriate Postgres role for the installed metabase.\nvim sql_jrn/33_semantic_annotation.jrn.sql\nRun the patch SQL by logging to the target database as postgres (or another authorized user; sudo -u postgres psql jrn_metabase) and issuing:\n\\i GitHub/LTER-core-metabase/sql_jrn/33_semantic_annotation.jrn.sql\nusing psql from the system prompt may work, though there may be permission problems with this:\npsql -U &lt;username&gt; -h &lt;hostname&gt; -d &lt;databasename&gt; &lt; GitHub/LTER-core-metabase/sql_jrn/33_semantic_annotation.sql\nCheck that the patch was applied correctly!",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#keeping-the-host-and-postgresql-up-to-date",
    "href": "docs/im/sysadmin/chapter-04-databases.html#keeping-the-host-and-postgresql-up-to-date",
    "title": "4. Databases",
    "section": "Keeping the host and PostgreSQL up to date",
    "text": "Keeping the host and PostgreSQL up to date\nThe JRN Metabase is usually hosted on a server running Linux or a similar OS. In the case of Ubuntu/Debian systems, keep the OS and PostgreSQL up to date with apt. Important tasks are listed below. For full documentation of PostgreSQL server administration see the official PG Administrator Guide.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#updating-lter_core_metabase",
    "href": "docs/im/sysadmin/chapter-04-databases.html#updating-lter_core_metabase",
    "title": "4. Databases",
    "section": "Updating LTER_core_metabase",
    "text": "Updating LTER_core_metabase\nPatches are periodically released and are available on the migration branch of the LTER GitHub repository. They are pretty easy to install (see setup document) but they may or may not be needed depending on how our database has evolved. Discuss with the patch creator before installing.\nIs there a way to export patches if we change things?",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#metabase-gotchas",
    "href": "docs/im/sysadmin/chapter-04-databases.html#metabase-gotchas",
    "title": "4. Databases",
    "section": "Metabase gotchas",
    "text": "Metabase gotchas\n\nPostgreSQL interprets any keyword (like functions) or identifier (table and column names) to lowercase unless they are double quoted. So, identifiers that are created as case-sensitive using double quotes will always have to be double quoted.\n\nOne common convention used when writing SQL is to type SQL keywords in all caps, and identifiers in lowercase with underscores (snake_case).\nCurrently LTER_core_metabase (and JRN Metabase) violates this - table names and column names are case sensitive and pretty much always need to be double quoted.\nSee discussion here.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#managing-roles-database-users",
    "href": "docs/im/sysadmin/chapter-04-databases.html#managing-roles-database-users",
    "title": "4. Databases",
    "section": "Managing roles (database users)",
    "text": "Managing roles (database users)\n\nAdministrator tasks to manage roles\n\nLog in to the psql shell either from a local terminal (sudo -u postgres psql) or from a remote client.\n psql -U &lt;role name&gt; -h &lt;host name or IP&gt; -p 5432 &lt;database name&gt;\nAdd a role for the user and assign a password:\n postgres=# CREATE ROLE &lt;name&gt; &lt;OTHER OPTIONS&gt; LOGIN;\n postgres=# ALTER USER &lt;name&gt; WITH ENCRYPTED PASSWORD '&lt;password&gt;';\nNote that LOGIN roles are needed to make initial connections to a database, so normal users should have this. CREATE USER grants LOGIN automatically.\nEmail the user the new role/user name and password and ask them to change their password using the instructions below.\nGrant or revoke the desired editing roles (list with \\du) to user roles:\n postgres=# GRANT group_role TO role1, ... ;\n postgres=# REVOKE group_role FROM role1, ... ;\nIn the case of LTER_core_metabase, the important roles are read_only_metabase and read_write_metabase.\nTo configure remote access (TCP/IP) for new users, they will need to be allowed in the pg_hba.conf file in some form. See the basics of this in the setup page and PostgreSQL specifics for the pg_hba.conf file.\n\n\n\nNew user tasks\nThe administrator (site IM for now), will email you a username and password that will allow you to login to the host and the PostgreSQL server. You will need to at least change the PostgreSQL server password for your user account.\n\nOpen a terminal on your computer and check to see if you have the PostgreSQL client (psql) installed. The command below should return version info. If it doesn‚Äôt you need to install psql.\n psql --version\nIssue the following command from your terminal:\n psql -U &lt;username&gt; -h &lt;host name or IP&gt; -p 5432 -c \"ALTER USER &lt;username&gt; WITH ENCRYPTED PASSWORD '&lt;new_password&gt;';\" &lt;database name&gt;\nwhere anything in angle brackets needs to be replaced with your username, server, and database information. Don‚Äôt forget to leave the single quotes around your new password, but you will leave them out when accessing the database.\n\nIf you don‚Äôt have psql available and can connect to jrn_metabase server with DBeaver, you may instead open an SQL console or SQL script window and type and execute this command:\n    ALTER USER &lt;username&gt; WITH ENCRYPTED PASSWORD '&lt;password&gt;';\nIn either case you will need to change the password in your locally-stored connection info (e.g.¬†for DBeaver and R) for future logins.\n\n\nDropping roles\nUser roles that no longer need access to a database or cluster should be dropped. The DROP ROLE SQL command will do this, as will the dropuser client application. Often a role will have ownership of database objects, so those ownerships need to be reassigned before dropping. See discussion here.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#copy-the-database",
    "href": "docs/im/sysadmin/chapter-04-databases.html#copy-the-database",
    "title": "4. Databases",
    "section": "Copy the database",
    "text": "Copy the database\nTo copy a database, including schema and data, use:\npostgres=# CREATE DATABASE &lt;new_database_name&gt; WITH TEMPLATE &lt;template_database_name&gt;;\nMore examples here.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#backup-the-database",
    "href": "docs/im/sysadmin/chapter-04-databases.html#backup-the-database",
    "title": "4. Databases",
    "section": "Backup the database",
    "text": "Backup the database\nTo backup the database the basic steps are to dump the database to an SQL file using the pg_dump utility:\npg_dump -F p the_db_name &gt; the_backup.sql \nSome options for pg_dump are:\n\n-F c|d|t|p output file format (custom, directory, tar, plain text)\n-C include commands to create database in dump\n-O no owner\n-s schema only\n-b include large objects in the dump\n-v verbose messages\n-f specifies the backup file name\n-d specifies the database to backup\n-U specifies the user to use\n-h specifies the host\n\nSo, to create a backup to a client machine, for example, run:\npg_dump -h &lt;hostname&gt; -U postgres -F p &lt;dbname&gt; &gt; ./path/dbname.bak.sql\nBackups using pg_dump can also be initiated from DBeaver or pgAdmin but not sure how yet.\nA backup can be restored with some variation of:\npsql the_db_name &lt; the_backup.sql\nBasic info here.\nRegular database backups and backup rotation should be scheduled on the server - probably with cron. There are some scripts in the lter_metabase_utils repository that are based on these.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#copy-development-jrn-metabase-to-production",
    "href": "docs/im/sysadmin/chapter-04-databases.html#copy-development-jrn-metabase-to-production",
    "title": "4. Databases",
    "section": "Copy development JRN Metabase to production",
    "text": "Copy development JRN Metabase to production\nThere are 2 versions of JRN metabase - a development copy called jrn_metabase_dev and the production version (jrn_metabase). Periodically, when the development database is well tested and stable, it should be copied to the production version. There are different ways to do this, the easiest of which is probably to delete jrn_metabase, create a new, empty database with that name, and then restore it with a nightly backup of jrn_metabase_dev.\nOn the host shell:\ndropdb jrn_metabase\nIn psql:\nCREATE DATABASE jrn_metabase;\nOn the host shell:\npsql -U &lt;username&gt; -d jrn_metabase -f /home/backups/postgresql/2021-04-06-daily/jrn_metabase_dev.sql\nThe nightly backup will need to be unzipped first. It is also possible do it all in psql with something like:\nDROP DATABASE jrn_metabase;\nCREATE DATABASE jrn_metabase WITH TEMPLATE jrn_metabase_dev;",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#migrate-a-database-to-a-new-host",
    "href": "docs/im/sysadmin/chapter-04-databases.html#migrate-a-database-to-a-new-host",
    "title": "4. Databases",
    "section": "Migrate a database to a new host",
    "text": "Migrate a database to a new host\nTo copy the database to a new host the basic steps are to dump the database to an SQL file using the pg_dump utility (see above), then copy this file to the new host and restore with:\npsql the_new_dev_db &lt; the_backup.sql\nThis can feasably all be done in one command:\npg_dump -C -h remotehost -U remoteuser dbname | psql -h localhost -U localuser dbname\nOr the SQL file can be dumped to localhost like this:\nssh remoteuser@remotehost \"pg_dump -U remoteuser dbname -h localhost -C --column-inserts\" &gt; ~/Desktop/dbname.bak.sql\nSee discussion here\nRoles are also important - to export roles and restore them in a new cluster use:\nssh remoteuser@remotehost \"pg_dumpall --roles-only -U remoteuser -h localhost\" &gt; ~/Desktop/dbname_roles.bak.sql\nSee here?\nRestoring seems to be easiest with a command like:\npg_restore -C -h localhost -d jstream-data -U postgres /home/backups/postgresql/2024-09-17-daily/jstream-data.custom\nTODO: Flesh this out - how we do backups, how to restore them, especially during a potential server upgrade or other change?",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#schema-overview",
    "href": "docs/im/sysadmin/chapter-04-databases.html#schema-overview",
    "title": "4. Databases",
    "section": "Schema overview",
    "text": "Schema overview\nThere are 4 schemas available in LTER-core-metabase, but the lter_metabase schema is the primary collection of tables for describing metadata and data packages. Within this schema there are 3 primary types of tables:\n\nEML-prefixed tables\n\nFor controlled vocabularies (CV) for elements of the EML schema, network level CVs (file types, unit dictionaries)\noften populated from network-level sources.\nInfrequently updated.\nCSV imports or patches might be the best way to populate\nFor now we are using what was already in LTER_core_metabase and hopefully updates will be community determined to some extent.\n\nList-prefixed tables\n\nControlled vocabularies more specific to the site\nWe will need to populate with JRN personnel, keyword thesauri, our sites (and bounding boxes), and possibly methods documents and taxa.\nOnly a subset of the LTER Keyword CV is currently present in the keywords list table.\nSomewhat frequently updated\nCSV imports or manual entry/updates to populate\n\nDataSet-prefixed tables\n\nMetadata assigned to specific datasets in the database\nEnter/update records anytime a dataset is added to or updated in JRN Metabase.\nPopulate with CSV imports, EML using EML2MB (see notes below), or ‚Äúmanually‚Äù by entering or updating metadata records for a dataset (see instructions below).",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#attributes-datasetattributes-and-datasetattributeenumeration-tables",
    "href": "docs/im/sysadmin/chapter-04-databases.html#attributes-datasetattributes-and-datasetattributeenumeration-tables",
    "title": "4. Databases",
    "section": "Attributes (DataSetAttributes and DataSetAttributeEnumeration tables)",
    "text": "Attributes (DataSetAttributes and DataSetAttributeEnumeration tables)\nStorage type refers to the data type in which attribute values are stored in EML (See EMLStorageTypes table). We use integer, float, string, date, and boolean types for our data.\nIn some ways storageType corresponds to MeasurementScaleDomainIDs\n\nCategorical attributes (\n\nnominalEnum: un-ordered categorical stored as a string or integer storageType\nordinalEnum: ordered categorical, usually stored as an integer\n\nNumeric attributes (\n\ninterval: un-ordered categorical stored as a string or integer storageType\nratio: ordered categorical, usually stored as an integer\n\n\nStuff on the internet about this:\n\nhttps://gradcoach.com/nominal-ordinal-interval-ratio/\nhttps://www.statology.org/levels-of-measurement-nominal-ordinal-interval-and-ratio/",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#some-thorny-issues",
    "href": "docs/im/sysadmin/chapter-04-databases.html#some-thorny-issues",
    "title": "4. Databases",
    "section": "Some thorny issues",
    "text": "Some thorny issues\n\nPersonnel\n\nThe contact person/org is assigned in the boilerplate table. Can there be more than one contact listed for a data package?\nIs there any way to place a single person in multiple roles for a data package? The schema seems to prevent this now.\nWhat about associated parties - how do they work between lter metabase and EDI?\nFor now there is a generic contact for every data package, and John is not listed as contact for anything that he was previously listed in.\n\nDataSetTemporal table\n\nI‚Äôm not sure how to populate this yet.\nIt needs to change as we update data packages and there doesn‚Äôt seem to be a way to automatically update it. Maybe part of our R scripts?\n\nDataSetSites\n\nNeeds to be populated but not sure what the best way is.\n\nThere doesn‚Äôt seem to be an easy way to tie geographicdescription to attributes.\nCodeID - we can list all codes used in datafiles in the ListCodes table, then reference in DatasetAttributeEnumeration. But should we?",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#editing-tools",
    "href": "docs/im/sysadmin/chapter-04-databases.html#editing-tools",
    "title": "4. Databases",
    "section": "Editing tools",
    "text": "Editing tools\nIn general we are using psql, python, or DBeaver to populate and edit our databases. DBeaver has excellent documentation, but users will need to install it and set it up with their user/role and password to log into JRN Metabases. PgAdmin and other tools might be useful too.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#populating-jrn-metabase-with-csv-imports",
    "href": "docs/im/sysadmin/chapter-04-databases.html#populating-jrn-metabase-with-csv-imports",
    "title": "4. Databases",
    "section": "Populating JRN Metabase with CSV imports",
    "text": "Populating JRN Metabase with CSV imports\nTables in JRN Metabase can be updated by importing CSV files containing metadata using psql, DBeaver, or python. The relevant SQL command is COPY FROM. Setting up incoming CSVs to match the table being copied to will help, and in LTER Metabases it will be best to start with parent tables (`DataSets‚Äô in particular?) so that foreign key rules won‚Äôt be violated.\nIn server-side psql use:\nCOPY persons(first_name, last_name, dob, email)\nFROM '/home/username/sampledb/persons.csv' \nDELIMITER ',' \nCSV HEADER;  # if there is a header in the csv\nIn client side psql use \\copy, and be aware that not all roles will be permitted to do client-site operations. All the columns in the csv need a destination column in the database table or else an error will result. This tutorial page helps.\nCOPY FROM operations with CSV files can also be initiated from python using a psycopg database connection. Some python scripts and modules for this are available in the jrn_metabase_tools repository.\nIn DBeaver, highlight the destination table and use the ‚ÄòImport‚Äô tool, then select the CSV file to import. The tool allows you to match columns between CSV and database tables and create/ignore columns if needed. Setting up incoming CSVs to match the tables in the schema beforehand will help. Documentation here.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#populate-with-eml",
    "href": "docs/im/sysadmin/chapter-04-databases.html#populate-with-eml",
    "title": "4. Databases",
    "section": "Populate with EML",
    "text": "Populate with EML\nThere is a tool being developed called EML2MB which might allow import of metadata using EML, but not ready for primetime yet.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#how-to-enter-or-update-a-dataset-manually-in-dataset-tables",
    "href": "docs/im/sysadmin/chapter-04-databases.html#how-to-enter-or-update-a-dataset-manually-in-dataset-tables",
    "title": "4. Databases",
    "section": "How to enter or update a dataset manually in DataSet tables",
    "text": "How to enter or update a dataset manually in DataSet tables\nThe DataSet-prefixed tables need to be added to or updated to add/update JRN Datasets in the database. These tables are all linked by the DataSetID columns, so new rows will need this key added, and updates to DataSets will need to take place with the correct DataSetIDs. These numbers correspond to the DataSet IDs we currently use for our JRN data packages (210001001, for example).\nBefore adding a new DataSet to the JRN Metabase, keep in mind that NOT ALL parts of the data package can be added directly to the database. The data entities (CCSVs or other files) and the abstract and methods documents (as .docx, markdown, etc) should be kept in a folder in our usual file system. You will add path to these files in JRN Metabase, but not the files themselves (for now). Once you have a folder to refer to, the order of operations to add a new dataset to JRN MEtabase is:\n\nIn the lter_metabase schema, open the DataSets table and add a new row.\nEnter a package ID in the DataSetID column.\nPopulate the rest of the row with the dataset title, path/name of the abstract file, the publication date, and other info.\nThe ‚ÄòBoilerplate‚Äô column has a parent table in the mb2eml_r schema that identifies seldom changing metadata elements such as .\nOpen the DataSetEntities table and enter information for the data entities. If there are more than one you will enter multiple new rows and order them in the `EntitySortOrder column. The DataSetID and EntitySortOrder columns together identify  in other tables, such as for ‚ÄúDataSetAttributes.‚Äù\nEdit the ‚ÄúDataSetAttributes‚Äù table\n\nRows containing a DataSetID and EntitySortOrder of one will be for describing the attribues in the first dataEntity included in the dataset.\n\n\n\nThings to remember\n\nMake sure there are not extra spaces entered in the database. For example, no extra spaces around the ‚ÄúColumnName‚Äù entries in DataSetAttributes table.\nColumn attributes with nominalEnum measurement scale types are tricky. To make them work:\n\nset the StorageType to integer or string, depending what they are\nshouldn‚Äôt need any Unit, NumberType or other values.\n\nFree text column attributes can have a nominalText measurement scale and a string StorageType.\n\nshouldn‚Äôt need any Unit, NumberType or other values.\n\nDon‚Äôt know how ordinalEnum and ordinalText measurement scales work yet. Can‚Äôt find much documentation about it, though the EML schema might define them.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#tools",
    "href": "docs/im/sysadmin/chapter-04-databases.html#tools",
    "title": "4. Databases",
    "section": "Tools",
    "text": "Tools\n\nSQL Workbench can compare database schemas and data (a Java app).\npsycopg is a PostgreSQL database driver for python.\nSQL Alchemy is an ORM and collection of database tools for python (it can use psycopg as a driver).\npeewee a lighter-weight ORM.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#setting-up-a-dataset-directory",
    "href": "docs/im/sysadmin/chapter-04-databases.html#setting-up-a-dataset-directory",
    "title": "4. Databases",
    "section": "Setting up a dataset directory",
    "text": "Setting up a dataset directory\nJornada datasets consist of data files, metadata, and sometimes additional files. Not all of these can be stored directly in the JRN Metabase. So, each Jornada dataset should have a dedicated directory, usually on the Jornada shared drive. These directories are typically prefixed with the Jornada dataset ID number. As noted below, all data entities to be incuded with the published dataset, as well as some metadata to be attached, will be stored in this directory. It is also a good place to store scripts used to QA/QC datafiles and publish finished datasets.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#creating-or-updating-a-dataset-manually-in-dataset-tables",
    "href": "docs/im/sysadmin/chapter-04-databases.html#creating-or-updating-a-dataset-manually-in-dataset-tables",
    "title": "4. Databases",
    "section": "Creating or updating a dataset manually in DataSet tables",
    "text": "Creating or updating a dataset manually in DataSet tables\nMetadata specific to datasets are stored in DataSet-prefixed tables in JRN Metabase. To create a new dataset record in JRN Metabase, new records (rows) must be added to these tables. To update an existing dataset in JRN Metabase, existing records in DataSet tables must be altered, and new records (rows) may be added. The DataSet tables are all linked by the DataSetID columns, so new records added to a table will require that this key be added, and updates to any dataset will need to take place in records with the correct, corresponding DataSetID. The DataSetID numbers in JRN Metabase correspond to the jornada dataset IDs we currently use for all our data packages (210001001, for example).\nBefore adding a new dataset to JRN Metabase, keep in mind that NOT ALL metadata for the data package will be added directly to the database. Long-form text metadata, particularly the abstract and methods for the dataset, are typically kept in the dataset directory as .docx, markdown or other text files. The filenames for the abstract and methods will be added to JRN Metabase, but not the metadata themselves.\nAdditionally, the data entities (CSV tables, geoTIFFs, zip archives, PDFs, etc‚Ä¶) that will be included with your dataset must also be in the dataset directory. You will add filenames for these to JRN Metabase, but not the files themselves.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#order-of-operations",
    "href": "docs/im/sysadmin/chapter-04-databases.html#order-of-operations",
    "title": "4. Databases",
    "section": "Order of operations",
    "text": "Order of operations\n\nIn the lter_metabase schema, open the DataSets table and add a new row.\nEnter a package ID in the DataSetID column.\nPopulate the rest of the row with the dataset title, name of the abstract file, publication date, and other info.\nThe ‚ÄòBoilerplate‚Äô column has a parent table in the mb2eml_r schema that identifies seldom changing metadata elements such as  and  metadata. Choose a boilerplate value that matches your project and dataset.\nOpen the DataSetEntities table and enter (or update) a record for each of the data entities. Each of these records refer to a file your dataset directory that will be published as part of the dataset.\n\nIf the dataset has more than one entity you will enter multiple new rows and order them in the EntitySortOrder column.\nThe DataSetID and EntitySortOrder columns together will be used to identify data entities in other tables, such as in the DataSetAttributes table (below).\n\nIf your data package has tabular data entities (DataSetEntities.EntityType=‚ÄúdataTable‚Äù) open the DataSetAttributes table to describe the columns in each tabular data entity.\n\nRows with an EntitySortOrder of ‚Äú1‚Äù will describe the column attributes in the first dataEntity included in the dataset.\nAdditional rows with the same DataSetID and incremented EntitySortOrders (2, 3, 4‚Ä¶) will describe column attributes in additional data entities for the dataset.\n\nIf the DataSetAttributes table defines any colums as categorical variables by having a MeasurementScaleDomain of ‚ÄúnominalEnum‚Äù, you will need look at the categorical data column in the data table and add a record for each categorical variable code used to the DataSetAttributeEnumeration table, using codes defined in the ListCodes table.\nContinue until all table are filled out‚Ä¶ a sensible order of operations from here (will add more detail later) would be to fill out:\n\nDataSetMethod with information about the methods file in your dataset directory, usually named ‚Äúmethods..md‚Äù or similar.\nDataSetKeywords with appropriate keywords chosen from the ListKeywords table.\nDataSetPersonnel with relevant personnel NameIDs chosen from the ListPeople table.\nDataSetSites with a site identifier chosen from the ListSites table.\nDataSetTemporal to define the time periods covered in the data.\n\n\nNote that many columns have constraints set - they will need to contain values, and these may be required to come from a parent table.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#things-to-remember-1",
    "href": "docs/im/sysadmin/chapter-04-databases.html#things-to-remember-1",
    "title": "4. Databases",
    "section": "Things to remember",
    "text": "Things to remember\n\nMake sure there are not extra spaces entered in the database. For example, no extra spaces around the ‚ÄúColumnName‚Äù entries in DataSetAttributes table.\nColumn attributes with nominalEnum measurement scale types are tricky. To make them work:\n\nset the StorageType to integer or string, depending what they are\nshouldn‚Äôt need any Unit, NumberType or other values.\n\nFree text column attributes can have a nominalText measurement scale and a string StorageType.\n\nshouldn‚Äôt need any Unit, NumberType or other values.\n\nDon‚Äôt know how ordinalEnum and ordinalText measurement scales work yet. Can‚Äôt find much documentation about it, though the EML schema might define them.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#postgresql-documentation",
    "href": "docs/im/sysadmin/chapter-04-databases.html#postgresql-documentation",
    "title": "4. Databases",
    "section": "PostgreSQL documentation",
    "text": "PostgreSQL documentation\n\nCurrent version docs\n\nThe tutorial (Part I) is useful for general learning.\nPart III, the Administration section covers topics like installation, server and database configuration, and managing roles.\nPart VI, the Reference section describes SQL commands and client/server tools like initdb, pg_dump, createdb and psql.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#platform-specific-packages-and-installation",
    "href": "docs/im/sysadmin/chapter-04-databases.html#platform-specific-packages-and-installation",
    "title": "4. Databases",
    "section": "Platform specific packages and installation",
    "text": "Platform specific packages and installation\n\nUbuntu and Ubuntu on Digital Ocean droplets\nDebian",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#tutorials",
    "href": "docs/im/sysadmin/chapter-04-databases.html#tutorials",
    "title": "4. Databases",
    "section": "Tutorials",
    "text": "Tutorials\n\nThe 4 Hour Learn PostgreSQL Tutorial is excellent.\nPostgreSQL Tutorials website\nGalaxQL (not specific to PostgreSQL, but fun)\n4 Hour Learn SQL Tutorial\nPostgreSQL Database Administration for beginners",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-04-databases.html#tools-1",
    "href": "docs/im/sysadmin/chapter-04-databases.html#tools-1",
    "title": "4. Databases",
    "section": "Tools",
    "text": "Tools\n\nSQL Workbench can compare database schemas and data (a Java app).\npsycopg is a PostgreSQL database driver for python.\nSQL Alchemy is an ORM and collection of database tools for python (it can use psycopg as a driver).\npeewee a lighter-weight ORM.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "4. Databases"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html",
    "title": "5. Data Publishing",
    "section": "",
    "text": "The steps to publish a dataset:\n\nStandardize and QA/QC a data file until it is in a publishable state\nAssemble and store all necessary metadata to describe the data\nMake a valid EML file (or other standardized metadata entry)\nPublish the dataset to a repository (like EDI)\n\nStep 1 we generally do with R. Step 2 happens in JRN_metabase. Steps 3 & 4 happen back in R with the jerald package.\n\n\n\n\nYou can use a free, online XML schema validator to validate your EML. Or you can use Oxygen, XML Notepad, XML Copy Editor, etc.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#overview",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#overview",
    "title": "5. Data Publishing",
    "section": "",
    "text": "The steps to publish a dataset:\n\nStandardize and QA/QC a data file until it is in a publishable state\nAssemble and store all necessary metadata to describe the data\nMake a valid EML file (or other standardized metadata entry)\nPublish the dataset to a repository (like EDI)\n\nStep 1 we generally do with R. Step 2 happens in JRN_metabase. Steps 3 & 4 happen back in R with the jerald package.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#some-useful-tools",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#some-useful-tools",
    "title": "5. Data Publishing",
    "section": "",
    "text": "You can use a free, online XML schema validator to validate your EML. Or you can use Oxygen, XML Notepad, XML Copy Editor, etc.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-the-r-environment",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-the-r-environment",
    "title": "5. Data Publishing",
    "section": "Set up the R environment",
    "text": "Set up the R environment\nInstall MetaEgress.\nIf you want to be adventurous, try installing jerald.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-a-dataset-directory",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-a-dataset-directory",
    "title": "5. Data Publishing",
    "section": "Set up a dataset directory",
    "text": "Set up a dataset directory\nJornada datasets consist of data files, metadata, and sometimes additional files. Not all of these can be stored directly in the JRN Metabase. So, each Jornada dataset should have a dedicated directory, usually on the Jornada shared drive. These directories are typically prefixed with the Jornada dataset ID number. As noted below, all data entities to be incuded with the published dataset, as well as some metadata to be attached, will be stored in this directory. It is also a good place to store scripts used to QA/QC datafiles and publish finished datasets.\nA template dataset directory for data packages that rely on JRN Metabase can be found in the jrn-metabase-utils repository. It contains all the directories and template scripts described below. This repository also contains a python script (init_jerald_datasetdir.py) that will build a dataset directory for you.\n\nMetadata sources\nIncoming metadata templates may be added to the metadata_docs/ or source_data/ directories, whichever is more convenient. Older metadata files used for reference, such as ‚Äúdsd‚Äù and ‚Äúprj‚Äù files from Jornada archives, should be kept in metadata_docs/.\nThe abstract and methods text files referred to in JRN Metabase (abstract.210000000.md and methods.210000000.md) should be kept in the top level of the dataset directory and can be updated there. With the exception of these two pieces of metadata, JRN Metabase is the primary store of metadata for Jornada datasets, and all changes should be made there.\n\n\nData table sources\nIncoming raw data, including submissions from researchers, can be kept in the source_data/ directory.\n\n\nOther entities\nOther entities should probably be kept in the top level of the dataset directory, but we may find a better way.\n\n\nBuild scripts\nBuild scripts here prepare the data and metadata for publication using various R packages. The resulting EML dataset may be published using the scripts, or manually using the EDI portal.\n\nbuild_210000000_dataset.R - Basic build script that formats & QA/QCs data in source_data/ and writes publishable data files to the working directory (./)\nbuild_210000000_eml.R - Creates an eml file and optionally uploads data entities and pushes the package to EDI using APIs.\nbuild_210000000_eml_jerald.R - same as above, but uses the jerald R package.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#build-eml-and-publish",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#build-eml-and-publish",
    "title": "5. Data Publishing",
    "section": "Build EML and publish",
    "text": "Build EML and publish\nFor now the build_210000000_eml.R template R script should have pretty good step-by-step information, but we‚Äôll document this further soon‚Ä¶",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-the-r-environment-1",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-the-r-environment-1",
    "title": "5. Data Publishing",
    "section": "Set up the R environment",
    "text": "Set up the R environment\nInstall EMLassemblyline.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-a-dataset-directory-1",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#set-up-a-dataset-directory-1",
    "title": "5. Data Publishing",
    "section": "Set up a dataset directory",
    "text": "Set up a dataset directory\nJornada datasets consist of data files, metadata, and sometimes additional files, so it is helpful to create dataset directories with a consistent structure to mange these files. Jornada dataset directories are typically prefixed with the Jornada dataset ID number. As noted below, all data entities to be incuded with the published dataset, all metadata for the EML document, and the scripts used to QA/QC datafiles and make EML documents should go in this directory. In the EAL documentation there is a dataset directory structure suggested, which we have adopted here.\nA template dataset directory for data packages that rely on EAL can be found in the jrn-emlassemblyline repository. It contains all the directories and template scripts described below. This repository also contains a python script (init_eal_datasetdir.py) that will build a dataset directory for you.\n\nMetadata sources\nMetadata should be added to the templates in the metadata_templates/ directory. These templates are described in the EAL documentation and there are templating functions that can be used to generate empty templates that are easy to fill in. Old metadata files used for reference, such as ‚Äúdsd‚Äù and ‚Äúprj‚Äù files from Jornada archives, can be kept in the top level dataset directory, or a subdirectory of your choice.\n\n\nData table sources\nIncoming raw data, including submissions from researchers, can be kept in the top level of the dataset directory. Once they are QA/QC‚Äôd and re-formatted for publication, the resulting data tables will be added to the data_entities/ subdirectory.\n\n\nOther entities\nOther entities, which are generally not processed or altered in any way before publication, can be put directly into the data_entities/ directory. However, there may be some cases where the incoming otherEntity file needs some alteration and it makes sense to keep a raw version separate from a processed version. Use your discretion.\n\n\nBuild scripts\nBuild scripts call EAL (and related R packages) to prepare the data and metadata for publication. Once complete, the resulting EML and data entities may be published manually using the EDI portal. Metadata such as the title and entity descriptions are also in these build scripts.\n\nbuild_&lt;datasetID&gt;.R - Basic build script that modifies data and writes EML for the dataset identified by .",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-05-data-publishing.html#build-eml-and-publish-1",
    "href": "docs/im/sysadmin/chapter-05-data-publishing.html#build-eml-and-publish-1",
    "title": "5. Data Publishing",
    "section": "Build EML and publish",
    "text": "Build EML and publish\nFor now the build_210000000.R template R script should have pretty good step-by-step information, but we‚Äôll document this further soon‚Ä¶\n\nDRAFT Steps to create metadata (EML) file\nThe example package with dataset ID 210000000 is used here.\nIf updating and publishing new data (and metadata):\n\nDownload and open the latest dataset.\nMake any data file changes necessary with R in the build_210000000.R script\nIncrement package.id version number in build_210000000.R (make_eml() call)\nIncrement the temporal.coverage array in build_210000000.R (make_eml() call)\nUpdate metadata templates.\nRun the build_210000000.R script in R.\nPublish to EDI staging server.\n\nIf you are updating the package metadata only:\n\nEdit the metadata templates in ./metadata_templates\nIncrement package.id version number in build_210000000.R (make_eml() call)\nRun the build_210000000.R script in R (careful not to regenerate blank templates)\nPublish to EDI or EDI Staging (‚ÄúEvaluate/Upload Data Packages‚Äù tool)",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "5. Data Publishing"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/index.html",
    "href": "docs/im/sysadmin/index.html",
    "title": "Full IM system docs",
    "section": "",
    "text": "Full IM system docs\nThis book contains everything you need to know if you are one of the IMs for the Jornada.",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation"
    ]
  },
  {
    "objectID": "docs/im/sysadmin/chapter-02-project-management.html",
    "href": "docs/im/sysadmin/chapter-02-project-management.html",
    "title": "2. Project Management",
    "section": "",
    "text": "Project management tasks and tools",
    "crumbs": [
      "IM Guide",
      "Full IM System Documentation",
      "2. Project Management"
    ]
  },
  {
    "objectID": "templates/fellowship_IM_statement.html",
    "href": "templates/fellowship_IM_statement.html",
    "title": "Jornada Data Commons",
    "section": "",
    "text": "To:¬†¬†¬†¬†Graduate Research Fellowship Program\n¬†¬†¬†¬†¬†¬†¬†¬†Jornada Basin LTER\n¬†¬†¬†¬†¬†¬†¬†¬†New Mexico State University\n¬†¬†¬†¬†¬†¬†¬†¬†Las Cruces, NM\n\nDate: 11 March 2025\nTo whom it may concern,\nThe student Arthur Tansley has, within the last year, completed the data and metadata submission requirements for funding by the Jornada Graduate Research Fellowship Program (‚Äúthe fellowship‚Äù). These requirements include:\n\nSubmission of one or more files containing data collected as part of a graduate research project associated with their degree program and the fellowship.\nSubmission of a complete metadata template describing the data in the file(s) above.\nThe student agrees to publicly release these data and metadata within one year of completing the degree program, or at the time the data are published in the peer-reviewed scientific literature (whichever occurs first).\n\nThe submitted data and metadata items (1 & 2) have been reviewed by the Jornada Basin LTER Information Manager and archived in the Jornada file system. Published products are listed below. Inclusion of this statement in a fellowship application constitutes the student‚Äôs agreement to requirement 3 and supports continued eligibility for the fellowship.\nSincerely,\n\nGreg Maurer\nInformation Manager for Jornada Basin LTER\nAvailable data:\n\nStover, D., J. McLaren, N. Pietrasiak, and L. Jin. 2024. Physical soil characteristics, microbial community composition, extracellular enzymatic activity, biologically based phosphorus (BBP) pools, and available phosphorus from two soil depths, four microhabitats, and four landforms at the Jornada Experimental Range, 2021. ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/9085a63e6ff1e310f13784b6fa0f8616 (Accessed 2025-03-11)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jornada Data Commons",
    "section": "",
    "text": "Welcome to the Jornada Data Commons. This site is maintained by the Jornada IM (Information Management) team to support researchers and data managers working with data from the Jornada Basin LTER (JRN) and Jornada Experimental Range (JER) programs."
  },
  {
    "objectID": "index.html#im-a-researcher-and-i-need-to",
    "href": "index.html#im-a-researcher-and-i-need-to",
    "title": "Jornada Data Commons",
    "section": "I‚Äôm a researcher and I need to‚Ä¶",
    "text": "I‚Äôm a researcher and I need to‚Ä¶\n\nGet approved to do research at the Jornada\nClean and describe my research data (data QA/QC, metadata)\nSubmit or publish a dataset\nUpdate project, personnel, or website information\nFind Jornada datasets or other information\nCite a Jornada dataset or funding\nLearn more about Jornada data management"
  },
  {
    "objectID": "index.html#im-a-data-manager-and-i-need-to",
    "href": "index.html#im-a-data-manager-and-i-need-to",
    "title": "Jornada Data Commons",
    "section": "I‚Äôm a data manager and I need to‚Ä¶",
    "text": "I‚Äôm a data manager and I need to‚Ä¶\n\nLearn more about a particular dataset\nFind templates, standards, or tools for data management\nRead or write the full IM system documentation"
  },
  {
    "objectID": "index.html#more-info",
    "href": "index.html#more-info",
    "title": "Jornada Data Commons",
    "section": "More info",
    "text": "More info\n\nPublications, presentations, videos, and other references\nJEDS (Jornada Environmental Data Science) tutorials"
  },
  {
    "objectID": "index.html#contact-us",
    "href": "index.html#contact-us",
    "title": "Jornada Data Commons",
    "section": "Contact us",
    "text": "Contact us\nFor questions about collecting, analyzing, publishing, and accessing Jornada data or metadata please contact the IM team (jornada.data@nmsu.edu)."
  }
]